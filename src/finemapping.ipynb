{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Finemapping benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Simulation of multivariate phenotypes due to multiple effects:\n",
    "\n",
    "- Take genotype data\n",
    "- Generate from ASH and MASH mixtures\n",
    "- With emphasize to LD convoluted regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Methods evaluated:\n",
    "\n",
    "- Variational methods:\n",
    "    - spike-slab, mixture normal, sum of single effects, m&m\n",
    "- Popular fine-mapping methods:\n",
    "    - DAP, FINEMAP, CAVIAR\n",
    "    \n",
    "[PAINTOR](https://github.com/gkichaev/PAINTOR_V3.0) is not included because current benchmark does not involve annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Commands for SuSiE paper\n",
    "\n",
    "## Actual commands used for SuSiE paper\n",
    "\n",
    "Computations of DSC are performed on The University of Chicago RCC Midway cluster. \n",
    "The files `*.yml` are relevant to settings on the cluster that assigns resource for different computational modules involved.\n",
    "\n",
    "To compare with methods on smaller simulations scenarios for effect variable $S = 1,2,3,4,5$ on smaller data (1000 variables):\n",
    "\n",
    "```\n",
    "dsc susie.dsc --target run_comparison -o susie_comparison --host susie_comparison.yml -c 60\n",
    "```\n",
    "\n",
    "To compare with DAP on $S = 10$ on full range of genotype data (~8K variables on average):\n",
    "\n",
    "```\n",
    "dsc susie.dsc --target hard_case -o hard_case --host hard_case.yml -c 60\n",
    "```\n",
    "\n",
    "It is also possible to run the benchmark on a local computer, if `--host` option is dropped. The `*.yml` files under `src` folder are still relevant in providing information on required resource for each DSC module. Running time of the benchmark depends on avaiable computational resource. It is estimated that the entire benchmark will take over a week to run on a single compute node with 28 Intel Xeon E5 CPU threads (some otehr fine-mapping methods are the speed bottleneck)\n",
    "\n",
    "To sync only relevant results to local computer:\n",
    "\n",
    "```\n",
    "#to_sync=susie_comparison\n",
    "to_sync=hard_case\n",
    "rsync -auzP --include=\"*/\" --exclude=\"*.ld_mat.rds\" --include=\"*.rds\" --include=\"*.pkl\" --include=\"*.pdf\" --include=\"*.png\" --include=\"*.db\"  --include=\"*.mpk\" --exclude=\"*\" <remote_url>:<path>/$to_sync ./\n",
    "```\n",
    "\n",
    "To pack up for distribution,\n",
    "\n",
    "```\n",
    "cd susie_comparison\n",
    "tar -zcf susie_comparison.tar.gz fit_caviar fit_dap fit_finemap fit_susie get_sumstats liter_data lm_less plot_caviar plot_dap plot_finemap plot_susie summarize_ld\n",
    " susie_comparison && cd ../hard_case\n",
    "tar -zcf hard_case.tar.gz fit_dap fit_susie10 full_data lm_less03 plot_dap plot_susie && cd ..\n",
    "tar cvf dsc-susie-paper.tar susie_comparison/susie_comparison* hard_case/hard_case*\n",
    "```\n",
    "\n",
    "## Commands for in house investigations\n",
    "\n",
    "```\n",
    "dsc susie.dsc --target run_susie\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table class=\"revision_table\">\n",
       "        <tr>\n",
       "        <th>Revision</th>\n",
       "        <th>Author</th>\n",
       "        <th>Date</th>\n",
       "        <th>Message</th>\n",
       "        <tr>\n",
       "        <tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/2bf3633bd3ccd7660f3d800e22ac17e2a48ce719/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">2bf3633<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-09</td>\n",
       "<td>Upgrade interface for null weight comparisons</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/73020d99f1af0bb7b199e2bb2867102186856a7e/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">73020d9<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-07</td>\n",
       "<td>Stop making plots</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/038a17464a5d02f2d78855c8a784f352c8dbdd70/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">038a174<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-07</td>\n",
       "<td>SuSiE interface updated to 0.4.30</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/e5bc582cb11bdae406368aadcfe9edcd91c96b56/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">e5bc582<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-03</td>\n",
       "<td>Update purity table extraction due to null_weight</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/5f15c3ab8f15b03071895da82afaa180c14abd30/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">5f15c3a<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-02</td>\n",
       "<td>Replace est_var with null_weight in results evaluation</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/7855ae4e6b8fedefbc5c11b675b7feadf64e7d21/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">7855ae4<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-10-01</td>\n",
       "<td>Evaluate null_weight; do not evaluate estimate_residual_variance for now</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/4ea4ad2598a0817aa8c71d1ee9b047146b06ec2a/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">4ea4ad2<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-09-14</td>\n",
       "<td>Update plot formats Fig 1 to 3</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/bacebfb05dc6eff9de34b383c43f8656fc4fe9b8/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">bacebfb<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-08-29</td>\n",
       "<td>Add notebook for Figure 1's example</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/b91fd966763d50524305b240a12a4e3129dad3d7/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">b91fd96<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-08-21</td>\n",
       "<td>Interface changes for susieR version 0.3</td></tr><tr><td><a target=\"_blank\" href=\"git@github.com:gaow/mvarbvs/blob/8a024476470e5e5381466f586150389e5091c460/GIT/github/mvarbvs/dsc/finemapping.ipynb\"><span class=\"revision_id\">8a02447<span></a></td>\n",
       "<td>Gao Wang</td>\n",
       "<td>2018-08-19</td>\n",
       "<td>Merge branch 'master' of http://github.com/gaow/mvarbvs</td></tr></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%revisions -n 10 --source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## DSC benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `zzz.dsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/zzz.dsc\" target=\"_blank\">modules/zzz.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/zzz.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/zzz.dsc\n",
    "%include modules/setup\n",
    "%include modules/simulate\n",
    "%include modules/fit\n",
    "%include modules/fit_susie\n",
    "%include modules/evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `master.dsc`\n",
    "\n",
    "Master DSC script. More of a show-off of what we have. Not to be fully executed any time soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"benchmark.dsc\" target=\"_blank\">benchmark.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to benchmark.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f benchmark.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  define:\n",
    "    get_data: full_data, lite_data, liter_data, two_effect\n",
    "    get_response: base_sim, original_Y\n",
    "    fit: (init_mnm * fit_mnm * plot_sse), \n",
    "        (fit_susie * plot_susie), \n",
    "        (fit_varbvs * plot_sse), \n",
    "        (fit_finemap * plot_finemap), \n",
    "        (fit_dap * plot_dap),\n",
    "        (fit_caviar * plot_caviar)\n",
    "  run: get_data * summarize_ld * get_response * get_sumstats * fit\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt\n",
    "    dap_g_data: dap-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `mnm.dsc`\n",
    "\n",
    "For M&M model development: M&M and compare with `susieR` + `varbvs`\n",
    "\n",
    "- `debug_mnm`: ELBO now works with `liter_data`, but not `lite_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"mnm.dsc\" target=\"_blank\">mnm.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to mnm.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f mnm.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  define:\n",
    "      setup: (full_data, lite_data, liter_data) * summarize_ld\n",
    "      get_response: base_sim, original_Y\n",
    "  run: \n",
    "    debug_mnm: setup * get_response * get_sumstats * init_mnm * fit_mnm_debug * plot_sse\n",
    "    run_mnm: setup * get_response * get_sumstats * init_mnm * fit_mnm * plot_sse\n",
    "    run_susie: setup * get_response * fit_susie * plot_sse\n",
    "    run_varbvs: setup * get_response * fit_varbvs * plot_sse\n",
    "    run_susie_uni: dap_g_data * original_Y * fit_susie * plot_sse\n",
    "    run_varbvs_uni: dap_g_data * original_Y * fit_varbvs * plot_sse\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt\n",
    "    dap_g_data: dap-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `susie.dsc`\n",
    "\n",
    "For SSE model development: compare with `DAP-g`, `FINEMAP`, `CAVIAR` and `varbvs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"susie.dsc\" target=\"_blank\">susie.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to susie.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f susie.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  run: \n",
    "    run_susie: liter_data * summarize_ld * simple_lm * fit_susie * plot_susie\n",
    "    run_varbvs: liter_data * summarize_ld * simple_lm * fit_varbvs * plot_sse\n",
    "    run_comparison: liter_data * summarize_ld * lm_less * get_sumstats * (fit_susie * plot_susie, fit_dap * plot_dap, fit_caviar, fit_finemap)\n",
    "    hard_case: full_data * lm_less03 * get_sumstats * (fit_susie10 * plot_susie, fit_dap * plot_dap)\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt\n",
    "    dap_g_data: dap-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `FINEMAP.dsc`\n",
    "\n",
    "A closer look into the FINEMAP program; and CAVIAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"FINEMAP.dsc\" target=\"_blank\">FINEMAP.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to FINEMAP.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f FINEMAP.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  define:\n",
    "    setup: (full_data, lite_data, liter_data) * summarize_ld\n",
    "    get_response: base_sim, original_Y\n",
    "  run:\n",
    "    run_finemap: setup * get_response * get_sumstats * fit_finemap * plot_finemap\n",
    "    run_finemap_uni: dap_g_data * original_Y * get_sumstats * fit_finemap * plot_finemap\n",
    "    run_caviar_uni: dap_g_data * original_Y * get_sumstats * fit_caviar * plot_caviar\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt\n",
    "    dap_g_data: dap-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `DAP-g.dsc`\n",
    "\n",
    "A closer look into the DAP-g program, mostly the same as `FINEMAP.dsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"DAP-g.dsc\" target=\"_blank\">DAP-g.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to DAP-g.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f DAP-g.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  define:\n",
    "    setup: (full_data, lite_data, liter_data) * summarize_ld\n",
    "    get_response: base_sim, original_Y\n",
    "  run:\n",
    "    run_dap_z_uni: dap_g_data * original_Y * get_sumstats * fit_dap_z * plot_dap\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt\n",
    "    dap_g_data: dap-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `GTEx.dsc`\n",
    "\n",
    "GTEx data analysis, using susie and DAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"GTEx.dsc\" target=\"_blank\">GTEx.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to GTEx.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f GTEx.dsc\n",
    "#!/usr/bin/env dsc\n",
    "%include modules/zzz\n",
    "\n",
    "DSC:\n",
    "  run: full_data * summarize_ld * original_Y * (fit_susie * plot_susie, fit_dap * plot_dap)\n",
    "  exec_path: modules\n",
    "  global:\n",
    "    data_file: gtex-manifest.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## DSC modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `setup.dsc`\n",
    "\n",
    "Data generators. See `20171103_MNMASH_Data.ipynb` for GTEx multitissue data preparation, if more real data are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/setup.dsc\" target=\"_blank\">modules/setup.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/setup.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/setup.dsc\n",
    "\n",
    "# Modules to provide data\n",
    "# Real or simulated\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# $data: full data\n",
    "# $sumstats: summary statistics\n",
    "\n",
    "full_data: sim_utils.R + R(data =readRDS(dataset);\n",
    "            data$X = as.matrix(data$X[,get_center(subset, ncol(data$X))]);\n",
    "            r = round(cor(data$X), 4);\n",
    "            saveRDS(r, ld_mat);\n",
    "            write.table(r,ld_file,quote=F,col.names=F,row.names=F))\n",
    "  tag: \"full\"\n",
    "  dataset: Shell{head -150 ${data_file}}\n",
    "  subset: NULL\n",
    "  $data: data\n",
    "  $top_idx: NA\n",
    "  $ld_file: file(ld)\n",
    "  $ld_mat: file(rds)\n",
    "        \n",
    "lite_data(full_data):\n",
    "  tag: \"2k\"\n",
    "  subset: 2000\n",
    "             \n",
    "liter_data(full_data):\n",
    "  tag: \"1k\"\n",
    "  subset: 1000\n",
    "            \n",
    "two_effect(full_data):\n",
    "  tag: \"two\"\n",
    "  subset: 2\n",
    "             \n",
    "dap_g_data(full_data): R(X = readRDS(dataset)$X;\n",
    "              r = round(cor(X), 4);\n",
    "              saveRDS(r, ld_mat);\n",
    "              write.table(r,ld_file,quote=F,col.names=F,row.names=F)) + \\\n",
    "              dap_g_paper.R + R(data = list(X=X,Y=Y,true_coef=B))  \n",
    "  tag: \"dap_g\"\n",
    "  dataset: Shell{cat ${dap_g_data}}\n",
    "             \n",
    "get_sumstats: regression.R + R(res = mm_regression(as.matrix(data$X), \n",
    "                                                   as.matrix(data$Y), data$Z))\n",
    "  @CONF: R_libs = abind\n",
    "  data: $data\n",
    "  $sumstats: res\n",
    "                                                   \n",
    "summarize_ld: lib_regression_simulator.py + \\\n",
    "                regression_simulator.py + \\\n",
    "                Python(res = summarize_LD(data['X'], ld_mat, ld_plot))\n",
    "  data: $data\n",
    "  ld_mat: $ld_mat\n",
    "  $ld_plot: file(png)\n",
    "  $top_idx: res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `simulate.dsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/simulate.dsc\" target=\"_blank\">modules/simulate.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/simulate.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/simulate.dsc\n",
    "\n",
    "# base_sim:\n",
    "# - A base simulator of 2 independent multivariate effects\n",
    "# - using MultivariateMixture\n",
    "# original_Yï¼š\n",
    "# - do not simulate data, just use original\n",
    "\n",
    "base_sim: lib_regression_simulator.py + \\\n",
    "                regression_simulator.py + \\\n",
    "                Python(data = simulate_main(data, conf, conf['cache']))\n",
    "  @CONF: python_modules = (seaborn, matplotlib, pprint)\n",
    "  data: $data\n",
    "  top_idx: $top_idx\n",
    "  n_signal: 3\n",
    "  n_traits: 2\n",
    "  eff_mode: \"mash_low_het\"\n",
    "  residual_mode: \"identity\"\n",
    "  swap_eff: True\n",
    "  keep_ld: True\n",
    "  center_data: True\n",
    "  cache: file(sim)\n",
    "  tag: \"sim1\"\n",
    "  @ALIAS: conf = Dict(!data, !eff_mode)\n",
    "  $data: data\n",
    "  $V: data['V']\n",
    "  $N: data['Y'].shape[0]\n",
    "\n",
    "simple_lm(base_sim):\n",
    "  eff_mode: \"simple_lm\"\n",
    "  amplitude: 0.6\n",
    "  pve: 0.05, 0.1, 0.2, 0.4\n",
    "  n_signal: 1, 2, 3, 4, 5\n",
    "\n",
    "lm_less(simple_lm):\n",
    "  pve: 0.2\n",
    "\n",
    "lm_less03(simple_lm):\n",
    "  pve: 0.3\n",
    "  n_signal: 10\n",
    "\n",
    "original_Y(base_sim):\n",
    "  eff_mode: \"original\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit.dsc`\n",
    "\n",
    "Fine mapping methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit.dsc\" target=\"_blank\">modules/fit.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit.dsc\n",
    "# workhorse(s) for finemapping\n",
    "\n",
    "# Module input\n",
    "# ============\n",
    "# $data: full data; or\n",
    "# $sumstats: summary statistics; or / and\n",
    "# $ld: LD information\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# $fitted: for diagnostics\n",
    "# $posterior: for inference\n",
    "\n",
    "init_mnm: init_mnm.R\n",
    "  # mashr comes from `dev` branch on github\n",
    "  @CONF: R_libs = mashr\n",
    "  V: $V\n",
    "  reg: $sumstats\n",
    "  # FIXME: these quantities are to be computed seperately and globally using mashr procedure\n",
    "  # See http://stephenslab.github.io/gtex-eqtls/analysis/20171002_MASH_V8.html\n",
    "  Sigma: \"empirical\"\n",
    "  (U, grid, p): (\"auto\", (0.9,0.01,0.01,0.01,0.01,0.01,0.01,0.02,0.02), \"auto\")\n",
    "  $model: model\n",
    "  $V: V\n",
    "\n",
    "fit_mnm_debug: regression.R + elbo_mnm.R + fit_mnm.R\n",
    "  @CONF: R_libs = mashr\n",
    "  maxL: 5\n",
    "  maxI: 20\n",
    "  get_elbo: TRUE\n",
    "  data: $data\n",
    "  model: $model\n",
    "  V: $V\n",
    "  $fitted: fitted_track\n",
    "  $posterior: posterior\n",
    "\n",
    "fit_mnm(fit_mnm_debug):\n",
    "  maxI: 10\n",
    "  get_elbo: FALSE\n",
    "\n",
    "fit_varbvs: setup_varbvs.R + fit_varbvs.R\n",
    "  @CONF: R_libs = varbvs@pcarbo/varbvs/varbvs-R\n",
    "  sa: 1\n",
    "  data: $data\n",
    "  $posterior: posterior\n",
    "  $fitted: fitted\n",
    "\n",
    "fit_caviar: fit_caviar.R + \\\n",
    "             R(posterior = finemap_mcaviar(sumstats[1,,]/sumstats[2,,], \n",
    "                                            ld, args, prefix=cache))\n",
    "  @CONF: R_libs = (dplyr, magrittr)\n",
    "  sumstats: $sumstats\n",
    "  ld: $ld_file\n",
    "  args: \"-g 0.001 -c 1\", \"-g 0.001 -c 2\", \"-g 0.001 -c 3\"\n",
    "  cache: file(CAVIAR)\n",
    "  $posterior: posterior\n",
    "\n",
    "fit_finemap(fit_caviar): fit_finemap.R + \\\n",
    "             R(posterior = finemap_mvar(sumstats[1,,] / sumstats[2,,],\n",
    "                                        ld, N, k,\n",
    "                                        args, prefix=cache))\n",
    "  N: $N\n",
    "  k: NULL\n",
    "  data: $data\n",
    "  args: \"--n-causal-max 1\", \"--n-causal-max 2\", \"--n-causal-max 3\"\n",
    "  cache: file(FM)\n",
    "\n",
    "fit_dap: fit_dap.py + Python(posterior = dap_batch(data['X'], data['Y'], cache, args))\n",
    "  data: $data\n",
    "  args: \"-ld_control 0.20 --all\"\n",
    "  cache: file(DAP)\n",
    "  $posterior: posterior\n",
    "\n",
    "fit_dap_z: fit_dap.py + Python(posterior = dap_batch_z(sumstats[0,:,:]/sumstats[1,:,:],\n",
    "                                                       ld, cache, args))\n",
    "  sumstats: $sumstats\n",
    "  ld: $ld_file\n",
    "  args: \"-t 4\"\n",
    "  cache: file(DAP)\n",
    "  $posterior: posterior\n",
    "\n",
    "# fit_dap_mv(fit_dap): fit_dap.py + Python(res = dap_mv())\n",
    "# fit_dap_mv_ss(fit_dap): fit_dap.py + Python(res = dap_mv_ss())         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_susie.dsc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_susie.dsc\" target=\"_blank\">modules/fit_susie.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_susie.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_susie.dsc\n",
    "fit_susie: fit_susie.R\n",
    "  # Prior variance of nonzero effects.\n",
    "  @CONF: R_libs = susieR@stephenslab/susieR\n",
    "  maxI: 200\n",
    "  maxL: 10\n",
    "  null_weight: 0, 0.5, 0.9, 0.95\n",
    "  prior_var: 0, 0.1, 0.4\n",
    "  data: $data\n",
    "  $posterior: posterior\n",
    "  $fitted: fitted\n",
    "\n",
    "fit_susie_auto: fit_susie.R\n",
    "  @CONF: R_libs = susieR@stephenslab/susieR\n",
    "  data: $data\n",
    "  prior_var: \"auto\"\n",
    "  $posterior: posterior\n",
    "  $fitted: fitted\n",
    "\n",
    "fit_susie01(fit_susie):\n",
    "  maxL: 1\n",
    "\n",
    "fit_susie10(fit_susie):\n",
    "  maxL: 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `evaluate.dsc`\n",
    "\n",
    "Methods evaluation / visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/evaluate.dsc\" target=\"_blank\">modules/evaluate.dsc</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/evaluate.dsc\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/evaluate.dsc\n",
    "# Modules to evaluate various methods\n",
    "# for finemapping-m\n",
    "\n",
    "# Module input\n",
    "# ============\n",
    "# $fit: see fit.dsc\n",
    "# $result: see fit.dsc\n",
    "\n",
    "# Module output\n",
    "# =============\n",
    "# ? an object or plot for diagnosis\n",
    "\n",
    "plot_finemap: plot_finemap.R\n",
    "  @CONF: R_libs = (dplyr, ggplot2, cowplot)\n",
    "  result: $posterior\n",
    "  top_rank: 10\n",
    "  $plot_file: file(png)\n",
    "\n",
    "plot_caviar(plot_finemap): plot_caviar.R\n",
    "plot_dap(plot_finemap): plot_dap.R\n",
    "\n",
    "plot_sse: lib_regression_simulator.py + \\\n",
    "            plot_sse.py + \\\n",
    "            Python(plot_sse(result['PosteriorMean'], data['true_coef'],\n",
    "                            result['in_CI'], ld_mat, plot_file))\n",
    "  @CONF: python_modules = seaborn\n",
    "  data: $data\n",
    "  result: $posterior\n",
    "  ld_mat: $ld_mat\n",
    "  $plot_file: file(plot_file)\n",
    "\n",
    "plot_susie: plot_susie.R\n",
    "  @CONF: R_libs = susieR\n",
    "  data: $data\n",
    "  result: $fitted\n",
    "  $plot_file: file(png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workhorses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `sim_utils.R`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/sim_utils.R\" target=\"_blank\">modules/sim_utils.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/sim_utils.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/sim_utils.R\n",
    "get_center <- function(k,n) {\n",
    "  ## For given number k, get the range k surrounding n/2\n",
    "  ## but have to make sure it does not go over the bounds\n",
    "  if (is.null(k)) {\n",
    "      return(1:n)\n",
    "  }\n",
    "  start = floor(n/2 - k/2)\n",
    "  end = ceiling(n/2 + k/2)\n",
    "  if (start<1) start = 1\n",
    "  if (end>n) end = n\n",
    "  return(start:end)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `regression.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/regression.R\" target=\"_blank\">modules/regression.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/regression.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/regression.R\n",
    "library(abind)\n",
    "mm_regression = function(X, Y, Z=NULL) {\n",
    "  if (!is.null(Z)) {\n",
    "      Z = as.matrix(Z)\n",
    "  }\n",
    "  reg = lapply(seq_len(ncol(Y)), function (i) simplify2array(susieR:::univariate_regression(X, Y[,i], Z)))\n",
    "  reg = do.call(abind, c(reg, list(along=0)))\n",
    "  # return array: out[1,,] is betahat, out[2,,] is shat\n",
    "  return(aperm(reg, c(3,2,1)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `setup_varbvs.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/setup_varbvs.R\" target=\"_blank\">modules/setup_varbvs.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/setup_varbvs.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/setup_varbvs.R\n",
    "\n",
    "X <- data$X\n",
    "storage.mode(X) <- \"double\"\n",
    "n <- nrow(X)\n",
    "p <- ncol(X)\n",
    "X <- scale(X,center = TRUE,scale = FALSE)\n",
    "alpha0  <- runif(p)\n",
    "alpha0  <- alpha0/sum(alpha0)\n",
    "mu0     <- rnorm(p)\n",
    "pp      <- rep(maxL/p, p)\n",
    "logodds <- varbvs:::logit(pp)\n",
    "Y <- data$Y\n",
    "for (r in 1:ncol(Y)) {\n",
    "  Y[,r] <- Y[,r] - mean(Y[,r])\n",
    "}\n",
    "storage.mode(Y) <- \"double\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_varbvs.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_varbvs.R\" target=\"_blank\">modules/fit_varbvs.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_varbvs.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_varbvs.R\n",
    "fitted <- list()\n",
    "for (r in 1:ncol(Y)) {\n",
    "  sigma <- var(Y[,r])\n",
    "  fitted[[r]] <- varbvs::varbvsnorm(X,Y[,r],sigma,sa,logodds,alpha0,mu0,update.order = 1:p,\n",
    "                                    update.sigma = FALSE,update.sa = FALSE,tol = 1e-6,\n",
    "                                    verbose = FALSE, maxiter=maxI)\n",
    "}\n",
    "\n",
    "post_mean <- do.call(cbind, lapply(1:length(fitted), function(i) fitted[[i]]$alpha * fitted[[i]]$mu))\n",
    "lfdr <- do.call(cbind, lapply(1:length(fitted), function(i) 1 - fitted[[i]]$alpha))\n",
    "posterior <- list(PosteriorMean=post_mean, lfdr=lfdr, in_CI=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `init_mnm.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/init_mnm.R\" target=\"_blank\">modules/init_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/init_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/init_mnm.R\n",
    "# Initialize model data: priors and init values\n",
    "\n",
    "if (Sigma != 'empirical') {\n",
    "  # FIXME data$V has to be changed\n",
    "  V = diag(nrow(V))\n",
    "}\n",
    "mash_data = mashr::mash_set_data(reg[1,,], Shat = reg[2,,], V = as.matrix(V))\n",
    "if (U == 'auto') {\n",
    "  U = mashr::cov_canonical(mash_data)\n",
    "} else {\n",
    "  ## FIXME: add other methods to get U\n",
    "  U = mashr::cov_canonical(mash_data)\n",
    "}\n",
    "model = list()\n",
    "if (p == 'auto') {\n",
    "  model$fitted_g = mashr::mash(mash_data, Ulist=U, outputlevel=1, usepointmass=TRUE)$fitted_g\n",
    "} else {\n",
    "  ## FIXME: need to use pre-fitted pi on larger data from mash procedure\n",
    "  model$fitted_g = list(pi=p, Ulist=U, grid=grid, usepointmass=TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `elbo_mnm.R`\n",
    "\n",
    "Here we compute ELBO along the lines of the FLASH paper: justify that it is the multivariate normal-mean problem (MASH), then computer ELBO mostly using MASH updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/elbo_mnm.R\" target=\"_blank\">modules/elbo_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/elbo_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/elbo_mnm.R\n",
    "#' @title Residual covariance for a M&M fit\n",
    "#' B is J X R matrix of M&M output\n",
    "#' SM is J X R X R matrix of M&M output with 2nd moment option on\n",
    "#' XtX is just precomputed t(X) %*% X\n",
    "compute_mnm_residual_covariance = function(X, Y, XtX, B, SM) {\n",
    "    # out = t(Y) %*% Y - 2 * t(B) %*% t(X) %*% Y # + E[B^TX^TXB]\n",
    "    # E[B^TX^TXB] is not easy to compute properly\n",
    "    # use MLE for now\n",
    "    return(t(Y - X%*%B) %*% (Y - X%*%B) / nrow(X))\n",
    "} \n",
    "                                            \n",
    "#' @title expected loglikelihood for a M&M fit\n",
    "# https://gaow.github.io/mvarbvs/writeup/20171215_MNMModel_Finemap.html\n",
    "#' S is simply XtX pre-computed\n",
    "#' Sigma is current estimate of residual variance\n",
    "#' B is J X R matrix of M&M output\n",
    "#' SM is J X R X R matrix of M&M output with 2nd moment option on\n",
    "compute_mnm_Eloglik = function(X,Y,S,Sigma,B,SM){\n",
    "    inv_Sigma = solve(Sigma)\n",
    "    det_Sigma = det(Sigma)\n",
    "    N = nrow(Y)\n",
    "    R = ncol(Y)\n",
    "    t0 = vector()\n",
    "    for (j in 1:ncol(X)) {\n",
    "        t0[j] = S[j,j] * sum(inv_Sigma * SM[,,j])\n",
    "    }\n",
    "    t1 = sum(diag(inv_Sigma %*% t(B) %*% S %*% B)) + sum(t0) -\n",
    "            2 * sum(diag(Y %*% inv_Sigma %*% t(B) %*% t(X))) +\n",
    "            sum(diag(Y %*% inv_Sigma %*% t(Y)))\n",
    "    out = -0.5 * N * R * log(2 * pi) - 0.5 * N * log(det_Sigma) - 0.5 * t1\n",
    "    return(out)\n",
    "}\n",
    "\n",
    "#' @title posterior expected loglikelihood for a MASH problem\n",
    "## E[log(\\hat{B}|B, Shat)]\n",
    "## Need posterior mean and posterior second moment from MASH\n",
    "## do not use any computational trick here because this is \n",
    "## just for sanity check\n",
    "compute_mash_Eloglik = function(betahat, Shat, b, b2) {\n",
    "    inv_Shat = solve(Shat)\n",
    "    det_Shat = det(Shat)\n",
    "    res = nrow(b) * log(2*pi) + log(det_Shat) +\n",
    "            (t(betahat) %*% inv_Shat %*% betahat -\n",
    "            2 * t(betahat) %*% inv_Shat %*% b +\n",
    "            sum(diag(inv_Shat %*% b2)))\n",
    "    return(-0.5 * res)\n",
    "}\n",
    "\n",
    "#' @title sum of MASH posterior expected loglikelihood\n",
    "#' Bhat is J x R matrix of MASH input\n",
    "#' SDhat is J X R matrix to be expanded with V, turning into J X R X R\n",
    "#' V is R X R matrix of MASH input\n",
    "#' Sigma is residual variance\n",
    "#' alpah is a J vector of weights\n",
    "#' B is J X R matrix of MASH output\n",
    "#' SM is J X R X R matrix of MASH output with 2nd moment option on\n",
    "compute_sse_Eloglik = function(Bhat, SDhat, V, Sigma, alpha, B, SM) {\n",
    "    ## FIXME: I think it is wrong here because it is not single effect model\n",
    "    ## where J effects should NOT be factorized.\n",
    "    ## But otherwise isn't it a matrix normal density with both row and column covariances?\n",
    "    res = vector()\n",
    "    for (j in 1:nrow(Bhat)) {\n",
    "        ## Is R X R\n",
    "        Shat = SDhat[j,] * t(V * SDhat[j,]) # faster than diag(SDhat[j,]) %*% V %*% diag(SDhat[j,])\n",
    "        ## Is R X 1\n",
    "        B_j = B[j,] * alpha[j]\n",
    "        ## 2nd moment, R X R\n",
    "        B2_j = (B[j,] %*% t(B[j,]) + SM[,,j]) * alpha[j]\n",
    "        res[j] = compute_mash_Eloglik(Bhat[j,], Shat, B_j, B2_j)\n",
    "    }\n",
    "    return(sum(res))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_mnm.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_mnm.R\" target=\"_blank\">modules/fit_mnm.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_mnm.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_mnm.R\n",
    "## M&M ash module core update\n",
    "mnm_update_model <- function(X, Y, V, fitted_g, fitted, get_kl = FALSE) {\n",
    "  ## \"fitted\" include p_alpha, alpha, mu and Xr\n",
    "  maxL = ncol(fitted$alpha)\n",
    "  for (l in 1:maxL) {\n",
    "    ## remove the lth effect\n",
    "    fitted$Xr <- fitted$Xr - X %*% (fitted$alpha[,l] * fitted$mu[[l]])\n",
    "    ## update mash model\n",
    "    reg <- mm_regression(X, Y - fitted$Xr)\n",
    "    mash_data <- mashr::mash_set_data(reg[1,,], Shat = reg[2,,], V = V)\n",
    "    mout <- mashr::mash(mash_data, g = fitted_g, fixg = TRUE, outputlevel=3)\n",
    "    ## update fitted values\n",
    "    fitted$mu[[l]] <- mout$result$PosteriorMean\n",
    "    fitted$s[[l]] <- mout$result$PosteriorCov\n",
    "    fitted$lfsr[[l]] <- mout$result$lfsr\n",
    "    fitted$neg[[l]] <- mout$result$NegativeProb\n",
    "    l10bf <- mashr::get_log10bf(mout)\n",
    "    ## FIXME: mashr issue 35\n",
    "    l10bf[is.infinite(l10bf)] <- range(l10bf, finite=TRUE)[2] * 100\n",
    "    alpha_post <- exp((l10bf - max(l10bf)) * log(10)) * fitted$p_alpha\n",
    "    fitted$alpha[,l] <- alpha_post / sum(alpha_post)\n",
    "    ## add back the updated lth effect\n",
    "    fitted$Xr <- fitted$Xr + X %*% (fitted$alpha[,l] * fitted$mu[[l]])\n",
    "    if (get_kl) {\n",
    "        # Justified by A.46 of FLASH paper\n",
    "        # Here KL is denoted as (13.28) of BDA 3\n",
    "        fitted$kl[l] <- -1 * mout$loglik + compute_sse_Eloglik(reg[1,,], reg[2,,], V,\n",
    "                                                               fitted$Sigma, \n",
    "                                                               fitted$alpha[,l],\n",
    "                                                               mout$result$PosteriorMean,\n",
    "                                                               mout$result$PosteriorCov)\n",
    "    }\n",
    "  }\n",
    "  return(fitted)\n",
    "}\n",
    "\n",
    "## Compute posterior mean and covariances\n",
    "mnm_compute_posterior_matrices = function(fitted, J, R, L) {\n",
    "    post_mean <- matrix(0, J, R)\n",
    "    for (l in 1:L) {\n",
    "      post_mean <- post_mean + fitted$mu[[l]] * fitted$alpha[,l]\n",
    "    }\n",
    "    post_cov <- array(0, dim=c(R, R, J))\n",
    "    for (j in 1:J) {\n",
    "      for (l in 1:L) {\n",
    "        post_cov[,,j] <- post_cov[,,j] + (fitted$mu[[l]][j,] %*% t(fitted$mu[[l]][j,]) + fitted$s[[l]][,,j]) * fitted$alpha[j,l]\n",
    "      }\n",
    "      post_cov[,,j] <- post_cov[,,j] - post_mean[j,] %*% t(post_mean[j,])\n",
    "    }\n",
    "    return(list(PosteriorMean = post_mean, PosteriorCov = post_cov))\n",
    "}\n",
    "\n",
    "## Initialize storage for results\n",
    "data$X <- as.matrix(data$X)\n",
    "data$Y <- as.matrix(data$Y)\n",
    "maxL <- min(maxL, ncol(data$X))\n",
    "p_alpha <- rep(1, ncol(data$X)) / ncol(data$X)\n",
    "alpha <- matrix(0, ncol(data$X), maxL)\n",
    "mu <- lapply(1:maxL, function(i) matrix(0, ncol(data$X), ncol(data$Y)))\n",
    "Xr <- matrix(0, nrow(data$Y), ncol(data$Y))\n",
    "fitted <- list(p_alpha=p_alpha, alpha=alpha, mu=mu, s=list(), Xr=Xr, kl=vector(), lfsr=list(), neg=list(), Sigma=V)\n",
    "fitted_track <- list()\n",
    "Vcorr <- cov2cor(V)\n",
    "## For ELBO\n",
    "XtX <- t(data$X) %*% data$X\n",
    "## Fit m&m model\n",
    "for (i in 1:maxI) {\n",
    "  fitted <- mnm_update_model(data$X, data$Y, Vcorr, model$fitted_g, fitted, get_elbo)\n",
    "  if (get_elbo) {\n",
    "      post_mat = mnm_compute_posterior_matrices(fitted, ncol(data$X), ncol(data$Y), maxL)\n",
    "      fitted$Sigma = compute_mnm_residual_covariance(data$X, data$Y, XtX,\n",
    "                                                     post_mat$PosteriorMean, \n",
    "                                                     post_mat$PosteriorCov)\n",
    "      fitted$post_loglik = compute_mnm_Eloglik(data$X, data$Y, \n",
    "                                          XtX, fitted$Sigma,\n",
    "                                          post_mat$PosteriorMean, \n",
    "                                          post_mat$PosteriorCov)\n",
    "      fitted$elbo = fitted$post_loglik - sum(fitted$kl)\n",
    "  }\n",
    "  fitted_track[[i]] <- fitted\n",
    "}\n",
    "\n",
    "post_mat = mnm_compute_posterior_matrices(fitted, ncol(data$X), ncol(data$Y), maxL)\n",
    "\n",
    "## Compute lfsr\n",
    "lfsr <- do.call(rbind, lapply(1:maxL, function(l) colSums(fitted$alpha[,l] * fitted$lfsr[[l]])))\n",
    "posterior <- list(PosteriorMean=post_mat$PosteriorMean,\n",
    "                  PosteriorCov=post_mat$PosteriorCov,\n",
    "                  alpha = fitted$alpha,\n",
    "                  lfsr=lfsr,\n",
    "                  n_in_CI=susieR:::n_in_CI(t(fitted$alpha)),\n",
    "                  in_CI=susieR:::in_CI(t(fitted$alpha))\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_susie.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_susie.R\" target=\"_blank\">modules/fit_susie.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_susie.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_susie.R\n",
    "library(susieR)\n",
    "fitted <- list()\n",
    "posterior <- list()\n",
    "for (r in 1:ncol(data$Y)) {\n",
    "  if ('Z' %in% names(data)) {\n",
    "      data$Y[,r] = residuals(lm(data$Y[,r]~Z, na.action=na.exclude))\n",
    "  }\n",
    "  if (prior_var == 'auto') {\n",
    "      fitted[[r]] <- susie_auto(data$X,data$Y[,r],L_max=100,tol=1e-3)\n",
    "  } else if (prior_var == 0) {\n",
    "      fitted[[r]] <- susie(data$X,data$Y[,r],\n",
    "                               L=maxL,\n",
    "                               max_iter=maxI,\n",
    "                               estimate_residual_variance=TRUE,\n",
    "                               estimate_prior_variance=TRUE,\n",
    "                               null_weight=null_weight,\n",
    "                               coverage=0.95,min_abs_corr=0.5,\n",
    "                               tol=1e-3)\n",
    "  } else {\n",
    "      fitted[[r]] <- susie(data$X,data$Y[,r],\n",
    "                               L=maxL,\n",
    "                               max_iter=maxI,\n",
    "                               estimate_residual_variance=TRUE,\n",
    "                               scaled_prior_variance=prior_var,\n",
    "                               null_weight=null_weight,\n",
    "                               coverage=0.95,min_abs_corr=0.5,\n",
    "                               tol=1e-3)\n",
    "  }\n",
    "  posterior[[r]] <- summary(fitted[[r]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_dap.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "DAP version 1 was published as Wen et al 2016 AJHG. Here William has polished the software `dap-g` with another manuscript that describes improved algorithm and working with summary statistics. This benchmark uses DAP version 2. Below is an example output that I parse and save.\n",
    "\n",
    "```\n",
    "Posterior expected model size: 0.500 (sd = 0.500)\n",
    "LogNC = -0.30685 ( Log10NC = -0.133 )\n",
    "Posterior inclusion probability\n",
    "\n",
    "((1))              7492 6.68581e-05       0.000 1\n",
    "((2))              7490 6.68581e-05       0.000 1\n",
    "... 7 lines\n",
    "((8))              7491 6.68046e-05       0.000 2\n",
    "((9))              7483 6.68046e-05       0.000 2\n",
    "((10))             7485 6.68046e-05       0.000 2\n",
    "... 13 lines\n",
    "((20))             7459 6.68046e-05       0.000 2\n",
    "((21))             7482 6.67422e-05       0.000 -1\n",
    "((22))             7489 6.67422e-05       0.000 -1\n",
    "... other lines until below ...\n",
    "\n",
    "Independent association signal clusters\n",
    "\n",
    "     cluster         member_snp      cluster_pip      average_r2\n",
    "       {1}              7            4.680e-04          0.951                 0.951   0.037\n",
    "       {2}             13            8.685e-04          0.623                 0.037   0.623\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_dap.py\" target=\"_blank\">modules/fit_dap.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_dap.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_dap.py\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def write_dap_full(x,y,prefix,r):\n",
    "    names = np.array([('geno', i+1, f'group{r}') for i in range(x.shape[1])])\n",
    "    with open(f'{prefix}.data', 'w') as f:\n",
    "        print(*(['pheno', 'pheno', f'group{r}'] + list(np.array(y).ravel())), file=f)\n",
    "        np.savetxt(f, np.hstack((names, x.T)), fmt = '%s', delimiter = ' ')\n",
    "#     grid = '''         \n",
    "#         0.0000  0.1000\n",
    "#         0.0000  0.2000\n",
    "#         0.0000  0.4000\n",
    "#         0.0000  0.8000\n",
    "#         0.0000  1.6000\n",
    "#         '''\n",
    "#     grid = '\\n'.join([x.strip() for x in grid.strip().split('\\n')])\n",
    "#     with open(f'{prefix}.grid', 'w') as f:\n",
    "#         print(grid, file=f)\n",
    "        \n",
    "def run_dap_full(prefix, args):\n",
    "    cmd = ['dap-g', '-d', f'{prefix}.data', '-o', f'{prefix}.result', '--output_all'] + ' '.join(args).split()\n",
    "    subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()    \n",
    "           \n",
    "def write_dap_ss(z,prefix):\n",
    "    '''z-score vesion of dap input is the same as FINEMAP'''\n",
    "    ids = np.array([str(i+1) for i in range(z.shape[0])])\n",
    "    with open(f'{prefix}.z', 'w') as f:\n",
    "        np.savetxt(f,  np.vstack((ids, z)).T, fmt = '%s', delimiter = ' ')\n",
    "\n",
    "def run_dap_z(ld, prefix, args):\n",
    "    cmd = ['dap-g', '-d_z', f'{prefix}.z', '-d_ld', ld, '-o', f'{prefix}.result', '--output_all'] + ' '.join(args).split()\n",
    "    subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()    \n",
    "    \n",
    "def extract_dap_output(prefix):\n",
    "    out = [x.strip().split() for x in open(f'{prefix}.result').readlines()]\n",
    "    pips = []\n",
    "    clusters = []\n",
    "    still_pip = True\n",
    "    for line in out:\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        if len(line) > 2 and line[2] == 'cluster_pip':\n",
    "            still_pip = False\n",
    "            continue\n",
    "        if still_pip and (not line[0].startswith('((')):\n",
    "            continue\n",
    "        if still_pip:\n",
    "            pips.append([line[1], float(line[2]), float(line[3]), int(line[4])])\n",
    "        else:\n",
    "            clusters.append([len(clusters) + 1, float(line[2]), float(line[3])])\n",
    "    pips = pd.DataFrame(pips, columns = ['snp', 'snp_prob', 'snp_log10bf', 'cluster'])\n",
    "    clusters = pd.DataFrame(clusters, columns = ['cluster', 'cluster_prob', 'cluster_avg_r2'])\n",
    "    clusters = pd.merge(clusters, pips.groupby(['cluster'])['snp'].apply(','.join).reset_index(), on = 'cluster')\n",
    "    return {'snp': pips, 'set': clusters}\n",
    "\n",
    "def dap_single(x, y, prefix, r, args):\n",
    "    write_dap_full(x,y,prefix,r)\n",
    "    run_dap_full(prefix,args)\n",
    "    return extract_dap_output(prefix)\n",
    "\n",
    "def dap_single_z(z, ld, prefix, args):\n",
    "    write_dap_ss(z,prefix)\n",
    "    run_dap_z(ld,prefix,args)\n",
    "    return extract_dap_output(prefix)\n",
    "\n",
    "def dap_batch(X, Y, prefix, *args):\n",
    "    return dict([(r, dap_single(X, Y[:,r], f'{prefix}_condition_{r+1}', r+1, args)) for r in range(Y.shape[1])])\n",
    "\n",
    "def dap_batch_z(z, ld, prefix, *args):\n",
    "    return dict([(r, dap_single_z(z[:,r], ld, f'{prefix}_condition_{r+1}', args)) for r in range(z.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_finemap.R`\n",
    "\n",
    "The wrapper implements an option to use parallel `lapply` which does not throw any error message (because each thread implements `try ... catch`). Only use it when all are tested to work. That is, when coding / changing the module the `parallel` switch should be turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_finemap.R\" target=\"_blank\">modules/fit_finemap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_finemap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_finemap.R\n",
    "#' FINEMAP I/O\n",
    "write_finemap_sumstats <- function(z, LD_file, n, k, prefix) {\n",
    "  cfg = list(z=paste0(prefix,\".z\"),\n",
    "             ld=LD_file,\n",
    "             snp=paste0(prefix,\".snp\"),\n",
    "             config=paste0(prefix,\".config\"),\n",
    "             k=paste0(prefix,\".k\"),\n",
    "             log=paste0(prefix,\".log\"),\n",
    "             meta=paste0(prefix,\".master\"))\n",
    "  write.table(z,cfg$z,quote=F,col.names=F)\n",
    "  if (!is.null(k)) {\n",
    "      write.table(t(k),cfg$k,quote=F,col.names=F,row.names=F)\n",
    "      write(\"z;ld;snp;config;k;log;n-ind\",file=cfg$meta)\n",
    "      write(paste(cfg$z, cfg$ld, cfg$snp, cfg$config, cfg$k, cfg$log, n, sep=\";\"),\n",
    "        file=cfg$meta,append=TRUE)\n",
    "  } else {\n",
    "      write(\"z;ld;snp;config;log;n-ind\",file=cfg$meta)\n",
    "      write(paste(cfg$z, cfg$ld, cfg$snp, cfg$config, cfg$log, n, sep=\";\"),\n",
    "            file=cfg$meta,append=TRUE)\n",
    "  }\n",
    "  return(cfg)\n",
    "}\n",
    "\n",
    "#' Run FINEMAP version 1.1\n",
    "#' http://www.christianbenner.com\n",
    "## FIXME: read the finemapr implementation for data sanity check.\n",
    "## Can be useful as a general data sanity checker (in previous modules)\n",
    "\n",
    "run_finemap <- function(z, LD_file, n, k, args = \"\", prefix=\"data\")\n",
    "{\n",
    "  cfg = write_finemap_sumstats(z, LD_file, n, k, prefix)\n",
    "  cmd = paste(\"finemap --sss --log\", \"--in-files\", cfg$meta, args)\n",
    "  dscrutils::run_cmd(cmd)\n",
    "\n",
    "  # read output tables\n",
    "  snp = read.table(cfg$snp,header=TRUE,sep=\" \")\n",
    "  snp$snp = as.character(snp$snp)\n",
    "\n",
    "  snp = rank_snp(snp)\n",
    "  config = read.table(cfg$config,header=TRUE,sep=\" \")\n",
    "\n",
    "  # extract number of causal\n",
    "  ncausal = finemap_extract_ncausal(cfg$log)\n",
    "  return(list(snp=snp, set=config, ncausal=ncausal))\n",
    "}\n",
    "\n",
    "rank_snp <- function(snp) {\n",
    "  snp <- arrange(snp, -snp_prob) %>%\n",
    "    mutate(\n",
    "        rank = seq(1, n()),\n",
    "        snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "    select(rank, snp, snp_prob, snp_prob_cumsum, snp_log10bf)\n",
    "  return(snp)    \n",
    "}\n",
    "\n",
    "finemap_extract_ncausal <- function(logfile)\n",
    "{\n",
    "  lines <- grep(\"->\", readLines(logfile), value = TRUE)\n",
    "  lines <- gsub(\"\\\\(|\\\\)|>\", \"\", lines)\n",
    "  splits <- strsplit(lines, \"\\\\s+\")\n",
    "  tab <- data.frame(\n",
    "    ncausal_num = sapply(splits, function(x) as.integer(x[2])),\n",
    "    ncausal_prob = sapply(splits, function(x) as.double(x[4])))\n",
    "  tab <- mutate(tab, type = ifelse(duplicated(ncausal_num), \"post\", \"prior\"))\n",
    "  return(tab)\n",
    "}\n",
    "\n",
    "finemap_mvar <- function(zscore, LD_file, n, k, args, prefix, parallel = FALSE) {\n",
    "  if (is.null(dim(zscore))) {\n",
    "      zscore = matrix(ncol=1,zscore)\n",
    "  }\n",
    "\n",
    "  single_core = function(r) \n",
    "      run_finemap(zscore[,r], LD_file, n, k, args, \n",
    "                  paste0(prefix, '_condition_', r))\n",
    "  if (parallel)\n",
    "      return(parallel::mclapply(1:ncol(zscore), function(r) single_core(r),\n",
    "                                mc.cores = min(8, ncol(zscore))))\n",
    "  else\n",
    "      return(lapply(1:ncol(zscore), function(r) single_core(r)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_finemap_v2.R`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Interface difference between version 1.1 and 1.2 (suprise!)\n",
    "- `--n-causal-max` changed to `--n-causal-snps`\n",
    "- Removed `--regions` option\n",
    "- Master file `n-ind` column changed to `n_samples`\n",
    "- And the most lack-of-consideration change is the input Z score format: now requires 8 columns, among which a required MAF column, and use beta and se instead of z score.\n",
    "\n",
    "```\n",
    "rsid chromosome position noneff_allele eff_allele maf beta se\n",
    "rs1 10 1 T C 0.35 0.0050 0.0208\n",
    "rs2 10 1 A G 0.04 0.0368 0.0761\n",
    "rs3 10 1 G A 0.18 0.0228 0.0199\n",
    "```\n",
    "\n",
    "and it is not clear that if eff_allele has to be minor allele -- does not make sense either way.\n",
    "\n",
    "Update: for some data-sets (same genotype LD different Z scores) FINEMAP will fail on error:\n",
    "\n",
    "```\n",
    "Error : Maximum likelihood estimate for the residual variance from multiple regression of SNPs is not positive!\n",
    "```\n",
    "\n",
    "With `parallel=TRUE` this module will not quit on error, but it will impact the plot module and cause it to fail. I've emailed the author with a test data-set. But for the time being I'll just ignore the data-sets that has this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_finemap_v2.R\" target=\"_blank\">modules/fit_finemap_v2.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_finemap_v2.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_finemap_v2.R\n",
    "#' FINEMAP I/O\n",
    "write_finemap_sumstats <- function(bhat, se, allele_freq, LD_file, n, k, prefix) {\n",
    "  cfg = list(z=paste0(prefix,\".z\"),\n",
    "             ld=LD_file,\n",
    "             snp=paste0(prefix,\".snp\"),\n",
    "             config=paste0(prefix,\".config\"),\n",
    "             k=paste0(prefix,\".k\"),\n",
    "             log=paste0(prefix,\".log\"),\n",
    "             meta=paste0(prefix,\".master\"))\n",
    "  # get dataset.z\n",
    "  J = length(bhat)\n",
    "  # FIXME: using minor allele frequency does not make sense\n",
    "  z = cbind(1:J, rep(1,J), rep(1,J), rep('A',J), rep('C',J), \n",
    "            pmin(allele_freq, 1-allele_freq), bhat, se)\n",
    "  colnames(z) = c('rsid', 'chromosome', 'position', 'noneff_allele', 'eff_allele',\n",
    "                  'maf', 'beta', 'se')\n",
    "  write.table(z,cfg$z,quote=F,col.names=T, row.names=F)\n",
    "  if (!is.null(k)) {\n",
    "      write.table(t(k),cfg$k,quote=F,col.names=F,row.names=F)\n",
    "      write(\"z;ld;snp;config;k;log;n_samples\",file=cfg$meta)\n",
    "      write(paste(cfg$z, cfg$ld, cfg$snp, cfg$config, cfg$k, cfg$log, n, sep=\";\"),\n",
    "        file=cfg$meta,append=TRUE)\n",
    "  } else {\n",
    "      write(\"z;ld;snp;config;log;n_samples\",file=cfg$meta)\n",
    "      write(paste(cfg$z, cfg$ld, cfg$snp, cfg$config, cfg$log, n, sep=\";\"),\n",
    "            file=cfg$meta,append=TRUE)\n",
    "  }\n",
    "  return(cfg)\n",
    "}\n",
    "\n",
    "#' Run FINEMAP version 1.2\n",
    "#' http://www.christianbenner.com\n",
    "## FIXME: read the finemapr implementation for data sanity check.\n",
    "## Can be useful as a general data sanity checker (in previous modules)\n",
    "\n",
    "run_finemap <- function(bhat, se, allele_freq, LD_file, n, k, args = \"\", prefix=\"data\")\n",
    "{\n",
    "  cfg = write_finemap_sumstats(bhat, se, allele_freq, LD_file, n, k, prefix)\n",
    "  cmd = paste(\"finemap --sss --log\", \"--in-files\", cfg$meta, args)\n",
    "  dscrutils::run_cmd(cmd)\n",
    "\n",
    "  # read output tables\n",
    "  snp = read.table(cfg$snp,header=TRUE,sep=\" \")[, c(\"rsid\", \"prob\", \"log10bf\")]\n",
    "  colnames(snp) = c(\"snp\", \"snp_prob\", \"snp_log10bf\")\n",
    "  snp$snp = as.character(snp$snp)\n",
    "\n",
    "  snp = rank_snp(snp)\n",
    "  config = read.table(cfg$config,header=TRUE,sep=\" \")[, 1:4]\n",
    "  colnames(config) = c('rank', 'config', 'config_prob', 'config_log10bf')\n",
    "\n",
    "  # Only keep configurations with cumulative 95% probability\n",
    "  config = within(config, config_prob_cumsum <- cumsum(config_prob))\n",
    "  config = config[config$config_prob_cumsum <= 0.95,]\n",
    "\n",
    "  # extract number of causal\n",
    "  ncausal = finemap_extract_ncausal(paste0(cfg$log, '_sss'))\n",
    "  return(list(snp=snp, set=config, ncausal=ncausal))\n",
    "}\n",
    "\n",
    "rank_snp <- function(snp) {\n",
    "  snp <- arrange(snp, -snp_prob) %>%\n",
    "    mutate(\n",
    "        rank = seq(1, n()),\n",
    "        snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "    select(rank, snp, snp_prob, snp_prob_cumsum, snp_log10bf)\n",
    "  return(snp)    \n",
    "}\n",
    "\n",
    "finemap_extract_ncausal <- function(logfile)\n",
    "{\n",
    "  lines <- grep(\"->\", readLines(logfile), value = TRUE)\n",
    "  lines <- gsub(\"\\\\(|\\\\)|>\", \"\", lines)\n",
    "  splits <- strsplit(lines, \"\\\\s+\")\n",
    "  tab <- data.frame(\n",
    "    ncausal_num = sapply(splits, function(x) as.integer(x[2])),\n",
    "    ncausal_prob = sapply(splits, function(x) as.double(x[4])))\n",
    "  tab <- mutate(tab, type = ifelse(duplicated(ncausal_num), \"post\", \"prior\"))\n",
    "  return(tab)\n",
    "}\n",
    "\n",
    "finemap_mvar <- function(bhat, se, allele_freq, LD_file, n, k, args, prefix, \n",
    "                         parallel = TRUE) {\n",
    "  if (is.null(dim(bhat))) {\n",
    "      bhat = matrix(ncol=1,bhat)\n",
    "  }\n",
    "  if (is.null(dim(se))) {\n",
    "      se = matrix(ncol=1,se)\n",
    "  }\n",
    "  single_core = function(r) \n",
    "      run_finemap(bhat[,r], se[,r], allele_freq, LD_file, n, k, args, \n",
    "                  paste0(prefix, '_condition_', r))\n",
    "  if (parallel)\n",
    "      return(parallel::mclapply(1:ncol(bhat), function(r) single_core(r),\n",
    "                                mc.cores = min(8, ncol(bhat))))\n",
    "  else\n",
    "      return(lapply(1:ncol(bhat), function(r) single_core(r)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `fit_caviar.R`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "`CAVIAR` output file (`*_post`): \n",
    "- column #1 is the variant name;\n",
    "- column #2 is the [posterior prob. that the variant is causal](https://github.com/fhormoz/caviar/issues/1#issuecomment-286521771);\n",
    "- column #3 is the amount that this variant contributes to 95%-causal credible set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/fit_caviar.R\" target=\"_blank\">modules/fit_caviar.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/fit_caviar.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/fit_caviar.R\n",
    "#' CAVIAR I/O\n",
    "write_caviar_sumstats <- function(z, prefix) {\n",
    "  cfg = list(z=paste0(prefix,\".z\"),\n",
    "             set=paste0(prefix,\"_set\"),\n",
    "             post=paste0(prefix,\"_post\"),\n",
    "             log=paste0(prefix,\".log\"))\n",
    "  write.table(z,cfg$z,quote=F,col.names=F)\n",
    "  return(cfg)\n",
    "}\n",
    "\n",
    "#' Run CAVIAR\n",
    "#' https://github.com/fhormoz/caviar\n",
    "\n",
    "run_caviar <- function(z, LD_file, args = \"\", prefix=\"data\")\n",
    "{\n",
    "  cfg = write_caviar_sumstats(z, prefix)\n",
    "  cmd = paste(\"CAVIAR\", \"-z\", cfg$z, \"-l\", LD_file, \"-o\", prefix, args)\n",
    "  dscrutils::run_cmd(cmd)\n",
    "  if(!all(file.exists(cfg$post, cfg$set, cfg$log))) {\n",
    "      stop(\"Cannot find one of the post, set, and log files\")\n",
    "  }\n",
    "  \n",
    "  log <- readLines(cfg$log)\n",
    "\n",
    "  # read output tables\n",
    "  snp <- read.delim(cfg$post)  \n",
    "  stopifnot(ncol(snp) == 3)\n",
    "  names(snp) <- c(\"snp\", \"snp_prob_set\", \"snp_prob\")\n",
    "  snp$snp <- as.character(snp$snp)\n",
    "  snp <- rank_snp(snp)\n",
    "\n",
    "  # `set` of snps\n",
    "  set <- readLines(cfg$set)\n",
    "  set_ordered <- left_join(data_frame(snp = set), snp, by = \"snp\") %>% \n",
    "    arrange(rank) %$% snp\n",
    "  return(list(snp=snp, set=set_ordered))\n",
    "}\n",
    "\n",
    "rank_snp <- function(snp) {\n",
    "  snp <- arrange(snp, -snp_prob) %>%\n",
    "    mutate(\n",
    "        rank = seq(1, n()),\n",
    "        snp_prob_cumsum = cumsum(snp_prob) / sum(snp_prob)) %>%\n",
    "    select(rank, snp, snp_prob, snp_prob_cumsum, snp_prob_set)\n",
    "  return(snp)    \n",
    "}\n",
    "\n",
    "finemap_mcaviar <- function(zscore, LD_file, args, prefix, parallel = FALSE) {\n",
    "  if (is.null(dim(zscore))) {\n",
    "      zscore = matrix(ncol=1,zscore)\n",
    "  }\n",
    "\n",
    "  single_core = function(r) \n",
    "      run_caviar(zscore[,r], LD_file, args, \n",
    "                  paste0(prefix, '_condition_', r))\n",
    "  if (parallel)\n",
    "      return(parallel::mclapply(1:ncol(zscore), function(r) single_core(r),\n",
    "                                mc.cores = min(8, ncol(zscore))))\n",
    "  else\n",
    "      return(lapply(1:ncol(zscore), function(r) single_core(r)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `plot_finemap.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_finemap.R\" target=\"_blank\">modules/plot_finemap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_finemap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_finemap.R\n",
    "\n",
    "plot_finemap <- function(x,\n",
    "                         grid_nrow = NULL, \n",
    "                         grid_ncol = NULL, \n",
    "                         label_size = 2,\n",
    "                         top_rank = 5,\n",
    "                         lim_prob = c(0, 1.2),\n",
    "                         ...)\n",
    "{\n",
    "  label_size_config = label_size\n",
    "  label_size_snp = label_size\n",
    "  top_rank_config = top_rank\n",
    "  top_rank_snp = top_rank\n",
    "  lim_prob_config = lim_prob\n",
    "  lim_prob_snp = lim_prob\n",
    "  lim_prob_ncausal = lim_prob   \n",
    "    \n",
    "  p1 <- plot_ncausal(x, \n",
    "    lim_prob = lim_prob_ncausal, ...)\n",
    "  p2 <- plot_set(x,  \n",
    "    top_rank = top_rank_config, \n",
    "    label_size = label_size_config, \n",
    "    lim_prob = lim_prob_config, ...)\n",
    "  p3 <- plot_snp(x, \n",
    "    top_rank = top_rank_snp,\n",
    "    label_size = label_size_snp, \n",
    "    lim_prob = lim_prob_snp, ...)\n",
    "  \n",
    "  plot_grid(p1, p2, p3,  labels = \"AUTO\", nrow = grid_nrow, ncol = grid_ncol)\n",
    "}\n",
    "\n",
    "\n",
    "plot_ncausal <- function(x, lim_prob, ...)\n",
    "{\n",
    "  ptab <- x$ncausal\n",
    "  \n",
    "  sum_prop_zero <- filter(ptab, ncausal_num == 0)[[\"prob\"]]  %>% sum\n",
    "  if(sum_prop_zero == 0) {\n",
    "    ptab <- filter(ptab, ncausal_num != 0)\n",
    "  }\n",
    "  \n",
    "  ptab <- mutate(ptab, \n",
    "    ncausal_num = factor(ncausal_num, levels = sort(unique(ncausal_num), \n",
    "                                                    decreasing = TRUE)),\n",
    "    type = factor(type, levels = c(\"prior\", \"post\")))\n",
    "    \n",
    "  p <- ggplot(ptab, aes(ncausal_num, ncausal_prob, fill = type)) + \n",
    "    geom_hline(yintercept = 1, linetype = 3) + \n",
    "    geom_bar(stat = \"identity\", position = \"dodge\") + \n",
    "    coord_flip() + theme(legend.position = \"top\") + \n",
    "    scale_fill_manual(values = c(\"grey50\", \"orange\")) +\n",
    "    ylim(lim_prob)\n",
    "    \n",
    "  return(p)\n",
    "}\n",
    "\n",
    "plot_set <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$set\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(config, \"\\n\", \n",
    "      \"P = \", round(config_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(config_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(config_prob, rank)) + \n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = config_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "\n",
    "plot_snp <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "  \n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    rank = seq(1, n()), \n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(snp_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "png(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_finemap(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `plot_caviar.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_caviar.R\" target=\"_blank\">modules/plot_caviar.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_caviar.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_caviar.R\n",
    "plot_caviar <- function(x,\n",
    "                        grid_nrow = NULL, \n",
    "                        grid_ncol = NULL, \n",
    "                        label_size = 2,\n",
    "                        top_rank = 5,\n",
    "                        lim_prob = c(0, 1.5),\n",
    "                        ...)\n",
    "{\n",
    "  plot_snp(x, label_size, top_rank, lim_prob, ...)\n",
    "}\n",
    "\n",
    "plot_snp <- function(x, label_size, top_rank, lim_prob, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"P(set) = \", round(snp_prob_set, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "png(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_caviar(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `plot_dap.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_dap.R\" target=\"_blank\">modules/plot_dap.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_dap.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_dap.R\n",
    "\n",
    "\n",
    "plot_dap <- function(x,\n",
    "                     grid_nrow = 2, \n",
    "                     grid_ncol = 1, \n",
    "                     label_size = 2,\n",
    "                     top_rank = 5,\n",
    "                     lim_prob = c(0, 1.2),\n",
    "                     ...)\n",
    "{\n",
    "  label_size_config = label_size\n",
    "  label_size_snp = label_size\n",
    "  top_rank_config = top_rank\n",
    "  top_rank_snp = top_rank\n",
    "  lim_prob_config = lim_prob\n",
    "  lim_prob_snp = lim_prob\n",
    "    \n",
    "  p2 <- plot_set(x,  \n",
    "    top_rank = top_rank_config, \n",
    "    label_size = label_size_config, \n",
    "    lim_prob = lim_prob_config, ...)\n",
    "  p3 <- plot_snp(x, \n",
    "    top_rank = top_rank_snp,\n",
    "    label_size = label_size_snp, \n",
    "    lim_prob = lim_prob_snp, ...)\n",
    "  \n",
    "  plot_grid(p2, p3,  labels = \"AUTO\", nrow = grid_nrow, ncol = grid_ncol)\n",
    "}\n",
    "\n",
    "\n",
    "plot_set <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$set\n",
    "\n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(cluster_prob, 2),\n",
    "      \"; \", \"avg(r^2) = \", round(cluster_avg_r2, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(cluster_prob, cluster)) + \n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = cluster_prob, yend = cluster, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(min(top_rank, nrow(ptab)) + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "\n",
    "plot_snp <- function(x, lim_prob, label_size, top_rank, ...)\n",
    "{\n",
    "  ptab <- x$snp\n",
    "  \n",
    "  ptab <- head(ptab, top_rank)\n",
    "\n",
    "  ptab <- mutate(ptab,\n",
    "    rank = seq(1, n()), \n",
    "    label = paste0(snp, \"\\n\", \n",
    "      \"P = \", round(snp_prob, 2),\n",
    "      \"; \", \"log10(BF) = \", round(snp_log10bf, 2)))\n",
    "\n",
    "  ggplot(ptab, aes(snp_prob, rank)) +\n",
    "    geom_vline(xintercept = 1, linetype = 3) + \n",
    "    geom_point() + \n",
    "    geom_segment(aes(xend = snp_prob, yend = rank, x = 0)) + \n",
    "    geom_text(aes(label = label), hjust = 0, nudge_x = 0.025, size = label_size) + \n",
    "    xlim(lim_prob) + \n",
    "    scale_y_continuous(limits  = c(top_rank + 0.5, 0.5), trans = \"reverse\")\n",
    "}\n",
    "\n",
    "png(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    print(plot_dap(result[[r]], top_rank = top_rank))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### `plot_susie.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_susie.R\" target=\"_blank\">modules/plot_susie.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_susie.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_susie.R\n",
    "\n",
    "png(plot_file)\n",
    "for (r in 1:length(result)) {\n",
    "    susie_plot(result[[r]], y='PIP', b=as.integer(data$true_coef[,r]))\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `plot_sse.py`\n",
    "\n",
    "**This script is obsolete since SuSiE version 0.4.29.302**. It can still be used after some work on the output object. \n",
    "I thus keep them here just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_sse.py\" target=\"_blank\">modules/plot_sse.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_sse.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_sse.py\n",
    "\n",
    "def plot_sse(coef, true_coef, in_set, ld, plot_prefix):\n",
    "    reg = RegressionData()\n",
    "    reg.set_xcorr(ld)\n",
    "    if in_set is not None:\n",
    "        in_set = np.sum(np.array(in_set), axis = 0)\n",
    "    coef = np.array(coef)\n",
    "    if true_coef is not None:\n",
    "        true_coef = np.array(true_coef)\n",
    "    for j in range(coef.shape[1]):\n",
    "        plot_file = f'{plot_prefix}.{j+1}.png'\n",
    "        reg.plot_property_vector(coef[:,j], None,\n",
    "                                 xz_cutoff = (0, 0.8), out = plot_file,\n",
    "                                 conf = {'title': f'Response {j+1}', \n",
    "                                    'ylabel': 'effect size estimate', \n",
    "                                    'zlabel': 'In 95% CS'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `plot_susie.py`\n",
    "\n",
    "**This script is obsolete since SuSiE version 0.4.29.302**. It can still be used after some work on the output object. \n",
    "I thus keep them here just in case.\n",
    "\n",
    "\n",
    "In addition to `plot_sse` which shows the single effects, here we summarize for each $l$ set:\n",
    "\n",
    "  - The size of 95% HPD interval\n",
    "  - The purity of it (defined by the smallest pair-wise LD)\n",
    "  - The minimum lfsr across conditions\n",
    "  \n",
    "we expect to see high correlation between small size, high purity and low lfsr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/plot_susie.py\" target=\"_blank\">modules/plot_susie.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/plot_susie.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/plot_susie.py\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "COLORS = ['#348ABD', '#7A68A6', '#A60628', '#467821', '#FF0000', '#188487', '#E2A233',\n",
    "              '#A9A9A9', '#000000', '#FF00FF', '#FFD700', '#ADFF2F', '#00FFFF']\n",
    "color_mapper = np.vectorize(lambda x: dict([(i,j) for i,j in enumerate(COLORS)]).get(x))\n",
    "\n",
    "class SusieReporter:\n",
    "    def __init__(self, in_cs, lfsr, true_coef, ld_mat):\n",
    "        self.nonzeros = [i for i, item in enumerate(true_coef) if item != 0]\n",
    "        self.ld = ld_mat        \n",
    "        self.cs = self.get_cs(in_cs)\n",
    "        self.lfsr = lfsr\n",
    "        self.signal_captured = []\n",
    "        if len(self.nonzeros):\n",
    "            for value in self.cs:\n",
    "                self.signal_captured.append([len([s for s in value if item >= s[0] and item <= s[1]]) > 0 for item in self.nonzeros])\n",
    "        self.n_in_cs = np.sum(in_cs, axis=1)\n",
    "        self.purity, self.purity_label = self.get_cs_purity()\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_set_positions(in_cs, max_pos):\n",
    "        positions = []\n",
    "        curr_len = 0\n",
    "        for b, g in itertools.groupby(in_cs):\n",
    "            lg = len(list(g))\n",
    "            if b:\n",
    "                positions.append((curr_len, curr_len + lg))\n",
    "            curr_len += lg\n",
    "        # remove the null weight case\n",
    "        if positions[-1][1] > max_pos:\n",
    "            positions = positions[:-1]\n",
    "        return positions\n",
    "    \n",
    "    def get_cs(self, in_cs):\n",
    "        cs = [self.get_set_positions(c, self.ld.shape[0]) for c in in_cs]\n",
    "        return [x for x in cs if len(x)]\n",
    "\n",
    "    def get_purity_values(self):\n",
    "        purity = []\n",
    "        for item in self.cs:\n",
    "            tmp = []\n",
    "            for ii in item:\n",
    "                value = np.array(np.absolute(self.ld[ii[0]:ii[1],ii[0]:ii[1]])).flatten()\n",
    "                value = [x for x in value if x < 1]\n",
    "                if len(value):\n",
    "                    tmp.append((np.min(value), np.mean(value), np.median(value), np.max(value)))\n",
    "                else:\n",
    "                    tmp.append((1,1,1,1))\n",
    "            purity.append(np.array(tmp))\n",
    "        return purity, {'min': 0, 'mean': 1, 'median': 2, 'max': 3}\n",
    "        \n",
    "    def plot_segments(self, seg_file, ld_type = 'min'):\n",
    "        if len(self.cs) == 0:\n",
    "            return None\n",
    "        lengths = np.concatenate([np.full(len(x), idx) for idx, x in enumerate(self.cs)])\n",
    "        lengths = np.array([(len(lengths) - idx, x) for idx, x in enumerate(lengths)])\n",
    "        sets = np.vstack(np.array(self.cs))\n",
    "        y, c, x1, x2 = np.hstack((lengths, sets)).T\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.vlines(self.nonzeros, 0, max(y), colors='#dcdcdc')\n",
    "        for idx, value in enumerate(self.cs):\n",
    "            keep = [j for j, item in enumerate(c) if item == idx]\n",
    "            singletons = [item for item in value if item[1] - item[0] == 1]\n",
    "            label = f'{idx+1}: {int(self.n_in_cs[idx])} vars, {sum(self.signal_captured[idx])}/{len(self.signal_captured[idx])} hit, min(LD)={self.purity[:,self.purity_label[ld_type]][idx]:.2f}, lfsr={self.lfsr[idx]:.2f}'\n",
    "            plt.hlines(np.take(y, keep), np.take(x1, keep), np.take(x2, keep), \n",
    "                       colors = color_mapper(np.take(c, keep)), label = label)\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        plt.yticks([])\n",
    "        plt.title(\"95% CS\")\n",
    "    #     plt.legend(loc='upper center', bbox_to_anchor=(0, -0.1),\n",
    "    #                 mode=\"expand\", borderaxespad=0, ncol=1)\n",
    "        plt.legend(bbox_to_anchor=(1.04,0.5), loc=\"center left\", borderaxespad=0)\n",
    "        plt.savefig(seg_file, dpi=500, bbox_inches='tight')                    \n",
    "        plt.gca()\n",
    "    \n",
    "    def plot_purity(self, purity_file, ld_type = 'min'):\n",
    "        lds, col_map = get_purity_values(self.cs, self.ld)\n",
    "        ld_idx = col_map[ld_type]\n",
    "        idx = 0\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        L = len(lds)\n",
    "        cols = 3\n",
    "        rows = L // cols + L % cols\n",
    "        position = range(1,L + 1)\n",
    "        for size, ld in zip(self.cs, lds):\n",
    "            x = np.array([s[1] - s[0] for s in size])\n",
    "            y = ld[:,ld_idx]\n",
    "            z = np.full(len(x), idx)\n",
    "            plt.subplot(rows,cols,position[idx])\n",
    "            idx += 1\n",
    "            label = f'L={idx}'\n",
    "            plt.scatter(x,y,c = color_mapper(z), label = label, marker = 'x')\n",
    "            plt.legend()\n",
    "        plt.subplots_adjust(hspace=0.3, wspace = 0.3)\n",
    "        plt.suptitle(f\"95% CI set sizes vs {ld_type}(abs(LD))\")\n",
    "        plt.savefig(purity_file, dpi=500, bbox_inches='tight')                    \n",
    "        plt.gca()\n",
    "    \n",
    "    def get_cs_purity(self):\n",
    "        lds = []\n",
    "        for item in self.cs:\n",
    "            idx = sum([list(range(x[0], x[1])) for x in item], [])\n",
    "            value = np.array(np.absolute(self.ld[idx,:][:,idx])).flatten()\n",
    "            value = [x for x in value if x < 1]\n",
    "            if len(value):\n",
    "                lds.append((np.min(value), np.mean(value), np.median(value), np.max(value)))\n",
    "            else:\n",
    "                lds.append((1,1,1,1))\n",
    "        return np.array(lds), {'min': 0, 'mean': 1, 'median': 2, 'max': 3}\n",
    "    \n",
    "def plot_sets(in_cs, lfsr, true_coef, ld_mat, seg_prefix, save_plot):\n",
    "    ld_status = dict()\n",
    "    signal_status = dict()\n",
    "    for idx, k in enumerate(in_cs.keys()):\n",
    "        reporter = SusieReporter(np.array(in_cs[k]), \n",
    "                                 np.array(lfsr)[:, idx], \n",
    "                                 np.array(true_coef)[:, idx], \n",
    "                                 ld_mat)\n",
    "        if save_plot:\n",
    "            reporter.plot_segments(f'{seg_prefix}.{idx+1}.png')\n",
    "        ld_status[idx+1] = reporter.purity\n",
    "        signal_status[idx+1] = reporter.signal_captured\n",
    "    return ld_status, signal_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Simulation under regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `lib_regression_simulator.py`\n",
    "\n",
    "- `RegressionData`: Stores multivariate $Y$ and multiple feature $X$ data.\n",
    "- `UnivariateMixture`: Simulating univariate effects with mixture distribution of effects: $\\beta$ are sampled from normal mixtures as described in Stephens 2017 the ASH paper.\n",
    "- `MultivariateMixture`: Multivariate mixture of Urbut 2017 the MASH paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/lib_regression_simulator.py\" target=\"_blank\">modules/lib_regression_simulator.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/lib_regression_simulator.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/lib_regression_simulator.py\n",
    "import numpy as np\n",
    "import os, copy\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pprint import pformat\n",
    "from collections import OrderedDict\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        try:\n",
    "            return self[item]\n",
    "        except KeyError:\n",
    "            raise AttributeError(item)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        return dotdict(copy.deepcopy(dict(self)))\n",
    "    \n",
    "class RegressionData(dotdict):\n",
    "    def __init__(self, X = None, Y = None, Z = None):\n",
    "        # FIXME: check if inputs are indeed numpy arrays\n",
    "        self.debug = dotdict()\n",
    "        self.x_mean = self.y_mean = self.z_mean = None\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Z = Z\n",
    "        self.xcorr = None\n",
    "\n",
    "    def get_summary_stats(self):\n",
    "        '''\n",
    "        Computer univariate regression for every X_j (N by 1) and Y_r (N by 1)\n",
    "        Bhat: J by R matrix of estimated effects\n",
    "        Shat: J by R matrix of SE of Bhat\n",
    "        '''\n",
    "        if self.Z is not None:\n",
    "            self.remove_covariates()\n",
    "        # Compute betahat\n",
    "        XtX_vec = np.einsum('ji,ji->i', self.X, self.X)\n",
    "        self.Bhat = (self.X.T @ self.Y) / XtX_vec[:,np.newaxis]\n",
    "        # Compute se(betahat)\n",
    "        Xr = self.Y - np.einsum('ij,jk->jik', self.X, self.B)\n",
    "        Re = np.einsum('ijk,ijk->ik', Xr, Xr)\n",
    "        self.Shat = np.sqrt(Re / XtX_vec[:,np.newaxis] / (self.X.shape[0] - 2))\n",
    "\n",
    "    def remove_covariates(self):\n",
    "        if self.Z is not None:\n",
    "            self.Y -= self.Z @ (np.linalg.inv(self.Z.T @ self.Z) @ self.Z.T @ self.Y)\n",
    "            self.Z = None\n",
    "\n",
    "    def center_data(self):\n",
    "        # for np.array: np.mean(Z, axis=0, keepdims=True)\n",
    "        # for np.matrix, no keepdims argument\n",
    "        if self.X is not None and self.x_mean is None:\n",
    "            self.x_mean = np.mean(self.X, axis=0)\n",
    "            self.X -= self.x_mean\n",
    "        if self.Y is not None and self.y_mean is None:\n",
    "            self.y_mean = np.mean(self.Y, axis=0)\n",
    "            self.Y -= self.y_mean\n",
    "        if self.Z is not None and self.z_mean is None:\n",
    "            self.z_mean = np.mean(self.Z, axis=0)\n",
    "            self.Z -= self.z_mean\n",
    "\n",
    "    def set_xcorr(self, xcorr=None):\n",
    "        if xcorr is not None:\n",
    "            self.xcorr = np.array(xcorr)\n",
    "        else:\n",
    "            self.xcorr = np.corrcoef(self.X, rowvar = False)\n",
    "            self.xcorr = (np.square(self.xcorr) * np.sign(self.xcorr)).astype(np.float16)\n",
    "\n",
    "    def plot_xcorr(self, out, limit = 5000, size = 15):\n",
    "        if isinstance(limit, tuple):\n",
    "            start = max(0, limit[0])\n",
    "            end = min(self.xcorr.shape[0], limit[1])\n",
    "            xcorr = self.xcorr[start:end,start:end]\n",
    "        else:\n",
    "            # the correlation matrix\n",
    "            limit = min(self.xcorr.shape[0], limit)\n",
    "            xcorr = self.xcorr[0:limit,0:limit]\n",
    "        # Generate a mask for the upper triangle\n",
    "        mask = np.zeros_like(xcorr, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        fig, ax = plt.subplots(figsize=(size,size))\n",
    "        if out.endswith('pdf'):\n",
    "            raise ValueError('Please use png extension for output file.')\n",
    "        print(f'Plotting figure {out} for {limit} markers (default limit set to 5000) ...')\n",
    "        use_abs = np.sum(xcorr < 0) == 0\n",
    "        cmap = sns.diverging_palette(250, 15, as_cmap=True)\n",
    "        sns.heatmap(xcorr, ax = ax, mask=mask, cmap = cmap, vmin=-1 if not use_abs else 0,\n",
    "                    vmax=1, square=True, xticklabels = False, yticklabels = False, \n",
    "                    linewidths=.5, cbar_kws={\"shrink\": .5}, center=0)  \n",
    "        ax = plt.gca()\n",
    "        print(f'Saving figure {out} ...')\n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def permute_X_columns(self):\n",
    "        '''\n",
    "        Permute X columns, i.e. break blocked correlation structure\n",
    "        '''\n",
    "        np.random.shuffle(self.X)\n",
    "        \n",
    "    def plot_property_vector(self, yaxis, zaxis, xz_cutoff = None, out = '/tmp/1.png',\n",
    "                            conf = {'title': '', 'ylabel': '', 'zlabel': ''}):\n",
    "        '''\n",
    "        - yaxis can be eg $\\beta$ or log10BF or -log10Prob\n",
    "        - zaxis can be some other quantity whose value will be \n",
    "        reflected by color shade\n",
    "        - xz_cutoff: (c1, c2). c1 is correlation cutoff to highlight\n",
    "        when c2 is satisfied by a given position on x-axis\n",
    "        '''\n",
    "        xaxis = [x+1 for x in range(len(yaxis))]\n",
    "        cmap = sns.cubehelix_palette(start=2.8, rot=.1, as_cmap=True)\n",
    "        f, ax = plt.subplots(figsize=(18,5))\n",
    "        if zaxis is not None:\n",
    "            points = ax.scatter(xaxis, yaxis, c=zaxis, cmap=cmap)\n",
    "            f.colorbar(points, label=conf['zlabel'])\n",
    "        else:\n",
    "            points = ax.scatter(xaxis, yaxis, cmap=cmap)\n",
    "        if xz_cutoff is not None and zaxis is not None:\n",
    "            c1, c2 = xz_cutoff\n",
    "            if len([i for i in zaxis if i > c2]) > 100:\n",
    "                print('Too many to highlight!')\n",
    "            else:\n",
    "                for idx, item in enumerate(zaxis):\n",
    "                    if item > c2:\n",
    "                        ax.scatter(xaxis[idx], yaxis[idx], s=80, \n",
    "                                   facecolors='none', edgecolors='r')\n",
    "                        for ii, xx in enumerate(self.xcorr[idx,:]):\n",
    "                            if xx > c1 and xx < 1.0:\n",
    "                                ax.scatter(xaxis[ii], yaxis[ii], \n",
    "                                           color='y', marker='+')\n",
    "        ax.set_title(conf['title'])\n",
    "        ax.set_ylabel(conf['ylabel'])\n",
    "        plt.gca()\n",
    "        plt.savefig(out, dpi = 500)\n",
    "        \n",
    "    def get_representative_features(self, block_r2 = 0.8, block_size = 10, max_indep_r2 = 0.02):\n",
    "        '''\n",
    "        Based on xcorr matrix, select \"most representative features\". \n",
    "        That is, these features are potentially most convoluted by other features (have stronger xcorr)\n",
    "        yet are independent among each other.\n",
    "        - block_r2: definition of correlated block -- abs squared correlation have to be > cutoff1\n",
    "        - block_size: define a large enough block -- block size have to be > block_size\n",
    "        - max_indep_r2: now select features that are completely independent -- r2 < max_indep_r2\n",
    "        '''\n",
    "        if self.xcorr is None:\n",
    "            self.set_xcorr(None)\n",
    "        # get r2 summary\n",
    "        r2 = pd.DataFrame(self.xcorr)\n",
    "        strong_r2_count = ((np.absolute(r2) > block_r2) * r2).sum(axis = 0).sort_values(ascending = False)\n",
    "        strong_r2_count = strong_r2_count[strong_r2_count > block_size]\n",
    "        # filter by r2\n",
    "        exclude = []\n",
    "        for x in strong_r2_count.index:\n",
    "            if x in exclude:\n",
    "                continue\n",
    "            for y in strong_r2_count.index:\n",
    "                if y in exclude or y == x:\n",
    "                    continue\n",
    "                if np.absolute(r2[x][y]) > max_indep_r2:\n",
    "                    exclude.append(y)\n",
    "        return [x for x in strong_r2_count.index if not x in exclude]\n",
    "\n",
    "    def __str__(self):\n",
    "        return pformat(self.__dict__, indent = 4)\n",
    "    \n",
    "class ResidualVariance:\n",
    "    def __init__(self, mode, dim = 1):\n",
    "        self.mode = mode\n",
    "        self.dim = dim\n",
    "        \n",
    "    def apply(self):\n",
    "        if self.mode == 'identity':\n",
    "            return self.set_identity()\n",
    "        else:\n",
    "            raise ValueError(f\"Residual mode {self.mode} not implemented.\")\n",
    "\n",
    "    def set_identity(self):\n",
    "        if self.dim > 1:\n",
    "            # multivariate case\n",
    "            return np.identity(self.dim)\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "class UnivariateMixture:\n",
    "    '''Simulated distributions of Stephens 2017 (ASH paper)'''\n",
    "    def __init__(self, dim):\n",
    "        self.size = dim\n",
    "        self.pi0 = 0\n",
    "        self.pis = []\n",
    "        self.mus = []\n",
    "        self.sigmas = []\n",
    "        self.coef = []\n",
    "        \n",
    "    def set_vanilla(self, amplitude):\n",
    "        self.pis = [1]\n",
    "        self.mus = [0]\n",
    "        self.sigmas = [amplitude]\n",
    "        \n",
    "    def set_pi0(self, pi0):\n",
    "        self.pi0 = pi0\n",
    "        \n",
    "    def set_spiky(self):\n",
    "        self.pis = [0.4,0.2,0.2,0.2]\n",
    "        self.mus = [0,0,0,0]\n",
    "        self.sigmas = [0.25,0.5,1,2]\n",
    "    \n",
    "    def set_near_normal(self):\n",
    "        self.pis = [2/3,1/3]\n",
    "        self.mus = [0,0]\n",
    "        self.sigmas = [1,2]\n",
    "        \n",
    "    def set_flat_top(self):\n",
    "        self.pis = [1/7] * 7\n",
    "        self.mus = [-1.5, -1, -.5 , 0, .5, 1, 1.5]\n",
    "        self.sigmas = [0.5] * 7\n",
    "        \n",
    "    def set_skew(self):\n",
    "        self.pis = [1/4,1/4,1/3,1/6]\n",
    "        self.mus = [-2,-1,0,1]\n",
    "        self.sigmas = [2,1.5,1,1]\n",
    "        \n",
    "    def set_big_normal(self):\n",
    "        self.pis = [1]\n",
    "        self.mus = [0]\n",
    "        self.sigmas = [4]\n",
    "\n",
    "    def set_bimodal(self):\n",
    "        self.pis = [0.5, 0.5]\n",
    "        self.mus = [-2, 2]\n",
    "        self.sigmas = [1, 1]\n",
    "        \n",
    "    def get_effects(self):\n",
    "        '''\n",
    "        beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N(mu_i, sigma_i)\n",
    "        '''\n",
    "        sigmas = np.diag(self.sigmas)\n",
    "        assert (len(self.pis), len(self.pis)) == sigmas.shape\n",
    "        masks = np.random.multinomial(1, self.pis, size = self.size)\n",
    "        mix = np.random.multivariate_normal(self.mus, sigmas, self.size)\n",
    "        self.coef = np.sum(mix * masks, axis = 1) * np.random.binomial(1, 1 - self.pi0, self.size)\n",
    "        \n",
    "    def swap_top_effects(self, given_index):\n",
    "        '''Set top effects to given indices\n",
    "        One can specify index, or use the \"top_index\"\n",
    "        generated by RegressionData.get_representative_features()\n",
    "        '''\n",
    "        given_index = np.array(given_index, dtype=int)\n",
    "        nb = np.zeros(len(self.coef))\n",
    "        beta = sorted(self.coef, key=abs, reverse=True)\n",
    "        for idx in given_infex:\n",
    "            nb[idx] = beta.pop(0)\n",
    "        np.random.shuffle(beta)\n",
    "        for idx in range(len(nb)):\n",
    "            if not idx in given_index:\n",
    "                nb[idx] = beta.pop(0)\n",
    "        assert len(beta) == 0\n",
    "        self.coef = np.array(nb)\n",
    "        \n",
    "    def sparsify_effects(self, num_non_zero, top_only = False):\n",
    "        '''\n",
    "        top_only: only keep top `num_non_zero` effects\n",
    "        '''\n",
    "        if top_only:\n",
    "            big_beta_index = [i[0] for i in sorted(enumerate(self.coef), key = lambda x: np.absolute(x[1]), reverse = True)]\n",
    "            selected_index = big_beta_index[:min(len(big_beta_index), num_non_zero)]\n",
    "        else:\n",
    "            selected_index = np.random.choice(np.arange(self.size), size=num_non_zero)\n",
    "        for j in range(self.size):\n",
    "            if j not in selected_index:\n",
    "                self.coef[j] = 0\n",
    "                \n",
    "    def get_y(self, regression_data, pve = None, sigma = None):\n",
    "        if sigma is None and pve is None:\n",
    "            raise ValueError('Need one of sigma or pve.')\n",
    "        if not (pve > 0 and pve < 1):\n",
    "            raise ValueError(f'PVE has to be between 0 and 1, not {pve}.')\n",
    "        if pve is not None:\n",
    "            genetic_var = np.var(np.dot(regression_data.X, self.coef.T))\n",
    "            pheno_var = genetic_var / pve\n",
    "            self.residual_variance = pheno_var - genetic_var\n",
    "        y = np.dot(regression_data.X, self.coef.T) + np.random.normal(0, np.sqrt(self.residual_variance), regression_data.X.shape[0])\n",
    "        # y.reshape(len(y), 1)\n",
    "        return y.T\n",
    "        \n",
    "    def __str__(self):\n",
    "        params = ' + '.join([\"{} N({}, {}^2)\".format(x,y,z) for x, y, z in zip(self.pis, self.mus, self.sigmas)])\n",
    "        return '{:.3f} \\delta_0 + {:.3f} [{}]'.format(self.pi0, 1 - self.pi0, params)\n",
    "    \n",
    "class MultivariateMixture:\n",
    "    '''FIXME: ideally implement Urbut 2017 simulated covs'''\n",
    "    def __init__(self, dim):\n",
    "        self.J, self.R = dim\n",
    "        self.pis = OrderedDict([('null', 0)])\n",
    "        self.Us = OrderedDict([('null', np.zeros((self.R, self.R)))])\n",
    "        self.mus = dict([('zeros', np.zeros(self.R))])\n",
    "        self.coef = []\n",
    "        self.grid = [0.1,0.5,1,2]\n",
    "        self._init_canonical()\n",
    "\n",
    "    def set_pi0(self, pi0):\n",
    "        self.pis['null'] = pi0\n",
    "        \n",
    "    def set_grid(self, grid):\n",
    "        self.grid = grid\n",
    "        \n",
    "    def _init_canonical(self):\n",
    "        '''\n",
    "        U is a dict of \n",
    "        - \"identity\" for the identity (effects are independent among conditions);\n",
    "        - \"singletons\" for the set of matrices with just one non-zero entry x_{jj} = 1 (j=1,...,R); (effect specific to condition j);\n",
    "        - \"equal_effects\" for the matrix of all 1s (effects are equal among conditions);\n",
    "        - \"simple_het\" for a set of matrices with 1s on the diagonal and all off-diagonal elements equal to pho; (effects are correlated among conditions).\n",
    "        '''\n",
    "        pho = [0.25, 0.5, 0.75]\n",
    "        self.Us['identity'] = np.identity(self.R)\n",
    "        for i in range(self.R):\n",
    "            self.Us[f'singleton_{i+1}'] = np.diagflat([1 if idx == i else 0 for idx in range(self.R)])\n",
    "        self.Us['equal_effects'] = np.ones((self.R, self.R))\n",
    "        for idx, item in enumerate(sorted(pho)):\n",
    "            self.Us[f'simple_het_{idx+1}'] = np.ones((self.R, self.R)) * item\n",
    "            np.fill_diagonal(self.Us[f'simple_het_{idx+1}'], 1)\n",
    "            \n",
    "    def set_shared(self):\n",
    "        '''\n",
    "        All weights are on equal effects\n",
    "        '''\n",
    "        self.pis['equal_effects'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "                \n",
    "    def set_low_het(self):\n",
    "        '''\n",
    "        All weights are on small het effects\n",
    "        '''\n",
    "        self.pis['simple_het_1'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "                \n",
    "    def set_indep(self):\n",
    "        '''\n",
    "        All weights are on identity effects\n",
    "        '''\n",
    "        self.pis['identity'] = 1 - self.pis['null']\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0\n",
    "\n",
    "    def set_singleton(self, index):\n",
    "        '''\n",
    "        All weights evenly set to given index of singleton effects\n",
    "        '''\n",
    "        index = [int(x) for x in index if x <= self.R and x > 1]\n",
    "        weight = (1 - self.pis['null']) / len(index)\n",
    "        for item in index:\n",
    "            self.pis[f'singleton_{item}'] = weight\n",
    "        for k in self.Us:\n",
    "            if k not in self.pis:\n",
    "                self.pis[k] = 0        \n",
    "        \n",
    "    def apply_grid(self):\n",
    "        def product(x,y):\n",
    "            for item in y:\n",
    "                yield x*item\n",
    "        self.Us = dict(sum([[(f\"{p}_{i+1}\", g) for i, g in enumerate(product(self.Us[p], np.square(self.grid)))] for p in self.Us if p != 'null'], []) + \\\n",
    "                      [('null', self.Us['null'])])\n",
    "        nG = len(self.grid)\n",
    "        for k in list(self.pis.keys()):\n",
    "            if k == 'null':\n",
    "                continue\n",
    "            for g in range(nG):\n",
    "                self.pis[f'{k}_{g+1}'] = self.pis[k] / nG\n",
    "            del self.pis[k]\n",
    "            \n",
    "    def get_effects(self):\n",
    "        '''\n",
    "        Generate B under multivariate normal mixture\n",
    "        beta ~ \\pi_0\\delta_0 + \\sum \\pi_i N(0, U_i)\n",
    "        '''\n",
    "        self.coef = np.zeros((self.J, self.R))\n",
    "        for j in range(self.J):\n",
    "            # sample distribution\n",
    "            dist_index = np.random.multinomial(1, list(self.pis.values()), size = 1).tolist()[0].index(1)\n",
    "            name = list(self.pis.keys())[dist_index]\n",
    "            self.coef[j,:] = np.random.multivariate_normal(self.mus['zeros'], self.Us[name], 1)\n",
    "        \n",
    "    def sparsify_effects(self, num_non_zero, top_only = False):\n",
    "        '''\n",
    "        top_only: only keep top `num_non_zero` effects\n",
    "        '''\n",
    "        if top_only:\n",
    "            beta_max = np.amax(np.absolute(self.coef), axis = 1)\n",
    "            big_beta_index = [i[0] for i in sorted(enumerate(beta_max), key = lambda x: x[1], reverse = True)]\n",
    "            selected_index = big_beta_index[:min(len(big_beta_index), num_non_zero)]\n",
    "        else:\n",
    "            selected_index = np.random.choice(np.arange(self.size), size=num_non_zero)\n",
    "        for j in range(self.J):\n",
    "            if j not in selected_index:\n",
    "                self.coef[j,:] = self.mus['zeros']\n",
    "                \n",
    "    def swap_top_effects(self, given_index):\n",
    "        '''Set top effects to given indices\n",
    "        One can specify index, or use the \"top_index\"\n",
    "        generated by RegressionData.get_representative_features()\n",
    "        '''\n",
    "        given_index = np.array(given_index, dtype=int)\n",
    "        nb = np.zeros(self.coef.shape)\n",
    "        beta_max = np.amax(np.absolute(self.coef), axis = 1)\n",
    "        big_beta_index = [i[0] for i in sorted(enumerate(beta_max), key = lambda x: x[1], reverse = True)]\n",
    "        for idx in given_index:\n",
    "            nb[idx,:] = self.coef[big_beta_index.pop(0),:]\n",
    "        for idx in range(nb.shape[0]):\n",
    "            if not idx in given_index:\n",
    "                nb[idx,:] = self.coef[big_beta_index.pop(0),:]\n",
    "        self.coef = nb\n",
    "        \n",
    "    def get_y(self, regression_data, sigma):\n",
    "        self.residual_variance = sigma\n",
    "        return regression_data.X @ self.coef + np.random.multivariate_normal(np.zeros(self.R), self.residual_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `regression_simulator.py`\n",
    "\n",
    "Simulator workhorses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/regression_simulator.py\" target=\"_blank\">modules/regression_simulator.py</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/regression_simulator.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/regression_simulator.py\n",
    "def summarize_LD(X, ld_input, ld_plot):\n",
    "    data = RegressionData()\n",
    "    data.X = X\n",
    "    data.set_xcorr(ld_input)\n",
    "    data.plot_xcorr(ld_plot)\n",
    "    return data.get_representative_features()\n",
    "\n",
    "def simulate_main(data, c, plot_prefix):\n",
    "    '''\n",
    "    data: $data\n",
    "    top_idx: $top_eff\n",
    "    n_signal: 3\n",
    "    n_traits: 2\n",
    "    eff_mode: mash_low_het\n",
    "    swap_eff: True\n",
    "    keep_ld: True\n",
    "    tag: sim1\n",
    "    @ALIAS: conf = Dict(!data, !eff_mode)\n",
    "    $data: data\n",
    "    '''\n",
    "    reg = RegressionData()\n",
    "    reg.X = data['X'].astype(float)\n",
    "    if eff_mode == 'original':\n",
    "        c['swap_eff'] = False\n",
    "    if c['swap_eff'] and c['top_idx'] is None:\n",
    "        raise ValueError(f'\"top_idx\" variable is not set by an upstream module')\n",
    "    if eff_mode == 'mash_low_het':\n",
    "        if c['n_traits'] < 2:\n",
    "            raise ValueError(f'Cannot simulate {c[\"n_traits\"]} under mode {eff_mode}')\n",
    "        data['true_coef'], data['residual_variance'] = mash_low_het(data, reg, c)\n",
    "    elif eff_mode == 'original':\n",
    "        data['true_coef'] = original_y(data, reg, c)\n",
    "        data['residual_variance'] = None\n",
    "    elif eff_mode == 'simple_lm':\n",
    "        data['true_coef'], data['residual_variance'] = simple_lm(data, reg, c)\n",
    "    else:\n",
    "        raise ValueError(f'Mode {eff_mode} is not implemented.')\n",
    "    if c['center_data']:\n",
    "        reg.center_data()\n",
    "    data['X'] = reg.X\n",
    "    data['Y'] = reg.Y\n",
    "    data['allele_freq'] = (reg.x_mean / 2) if reg.x_mean is not None else (np.mean(reg.X, axis=0) / 2)\n",
    "    data['allele_freq'] = data['allele_freq'].T\n",
    "    if data['true_coef'] is not None:\n",
    "        for j in range(data['true_coef'].shape[1]):\n",
    "            plot_file = f'{plot_prefix}.{j+1}.png'\n",
    "            reg.plot_property_vector(data['true_coef'][:,j], \n",
    "                                 [np.absolute(x)>0 for x in data['true_coef'][:,j]], \n",
    "                                 xz_cutoff = None, out = plot_file,\n",
    "                                conf = {'title': f'Response {j+1}', \n",
    "                                        'ylabel': 'effect size', 'zlabel': ''})\n",
    "    if data['Y'].shape[1] == 1:\n",
    "        data['V'] = np.cov(data['Y'][:,0])\n",
    "    else:\n",
    "        data['V'] = np.cov(data['Y'], rowvar = False)\n",
    "    return data\n",
    "        \n",
    "def original_y(data, reg, c):\n",
    "    if 'y' in data:\n",
    "        reg.Y = data.pop('y')\n",
    "    elif isinstance(data['Y'], pd.DataFrame):\n",
    "        reg.Y = np.vstack(data['Y'].values()).T\n",
    "    else:\n",
    "        reg.Y = data['Y']\n",
    "    return None if 'true_coef' not in data else np.array(data['true_coef'])\n",
    "\n",
    "def simple_lm(data, reg, c):\n",
    "    if 'Z' in data:\n",
    "        del data['Z']\n",
    "    if 'y' in data:\n",
    "        del data['y']\n",
    "    eff = UnivariateMixture(reg.X.shape[1])\n",
    "    eff.set_vanilla(c['amplitude'])\n",
    "    Y = []\n",
    "    coef = []\n",
    "    sigma = []\n",
    "    for i in range(c['n_traits']):\n",
    "        eff.get_effects()\n",
    "        eff.sparsify_effects(c['n_signal'])\n",
    "        Y.append(eff.get_y(reg, pve = c['pve']))\n",
    "        coef.append(eff.coef)\n",
    "        sigma.append(eff.residual_variance)\n",
    "    reg.Y = np.hstack(Y)\n",
    "    return np.array(coef).T, np.array(sigma)\n",
    "    \n",
    "def mash_low_het(data, reg, c):\n",
    "    if not c['keep_ld']:\n",
    "        reg.permuate_X_columns()\n",
    "        data['X'] = reg.X\n",
    "    eff = MultivariateMixture((data['X'].shape[1], c['n_traits']))\n",
    "    eff.set_low_het()\n",
    "    eff.apply_grid()\n",
    "    eff.get_effects()\n",
    "    if c['swap_eff']:\n",
    "        eff.swap_top_effects(c['top_idx'])\n",
    "    eff.sparsify_effects(c['n_signal'])\n",
    "    reg.Y = eff.get_y(reg, ResidualVariance(c['residual_mode'], eff.R).apply())\n",
    "    return eff.coef, eff.residual_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### `dap_g_paper.R`\n",
    "\n",
    "Simulation from DAP-g paper, code on [dap-g github](https://github.com/xqwen/dap/tree/master/dap-g_paper/simulation/data_generation).\n",
    "\n",
    "> We set up a simulation scenario mimickingcis-eQTL mapping in a practical setting. In particular, we use the real genotype data from 343 European individuals from the GUEVADIS project. We artificially construct a genomic region of 1,001 SNPs. The region is divided into 91 LD blocks, and each block contains 11 SNPs. All LD blocks are selected from chromosome 1, and the consecutive blocks are at least 1Mb apart. With this construction scheme, the LD only presents within each block, and the SNP genotypes are mostly uncorrelated across blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "kernel": "R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"sos_hint\">Cell content saved to <a href=\"modules/dap_g_paper.R\" target=\"_blank\">modules/dap_g_paper.R</a></div>"
      ],
      "text/plain": [
       "Cell content saved to modules/dap_g_paper.R\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%save -f modules/dap_g_paper.R\n",
    "## args = commandArgs(trailingOnly=TRUE)\n",
    "## index = args[1]\n",
    "## X = as.matrix(read.table(\"sim.r.geno\"))\n",
    "n = dim(X)[1]      # number of observations\n",
    "p = dim(X)[2]      # number of variables\n",
    "freq = 0.05\n",
    "\n",
    "region = rbinom(91,1,freq)\n",
    "amplitude = 0.6\n",
    "\n",
    "get.beta<-function(v){\n",
    "  rstv = rep(0,11)\n",
    "  if(v==1){\n",
    "    index = sample(1:11,1)\n",
    "    rstv[index]=rnorm(1,sd=amplitude);\n",
    "\n",
    "  }\n",
    "  return(rstv)\n",
    "}\n",
    "\n",
    "beta = as.vector(sapply(region, get.beta))\n",
    "\n",
    "y.sample <- function() X %*% beta + rnorm(n)\n",
    "\n",
    "Y = matrix(ncol=1,y.sample())\n",
    "B = matrix(ncol=1,beta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.17.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
